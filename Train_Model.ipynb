{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import logging\n",
    "import importlib\n",
    "import shutil\n",
    "\n",
    "#MY_DIRNAME = os.path.dirname(os.path.abspath(states))\n",
    "#sys.path.insert(0, os.path.join(MY_DIRNAME, '..'))\n",
    "\n",
    "# TODO: import net \n",
    "from yolo_model import yoloModel\n",
    "from PASCAL_Dataloader import create_split_loaders\n",
    "from YOLO_Loss import YoloLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    config['global_step'] = config.get('start_step', 0)\n",
    "    is_training = False if config.get('export_onnx') else True\n",
    "\n",
    "    # TODO: Load and initialize network\n",
    "    net = yoloModel(config)\n",
    "\n",
    "    # Define the optimizer and learning rate\n",
    "    optimizer = obtain_optimizer(config, net)\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer,\n",
    "        step_size=config['decay_step'],\n",
    "        gamma=config['decay_gamma'])\n",
    "\n",
    "    # Use pretrained model\n",
    "    if config['pretrain_snapshot']:\n",
    "        logging.info('Load pretrained weights from {}'.format(config['pretrain_snapshot']))\n",
    "        state_dict = torch.load(config['pretrain_snapshot'])\n",
    "        net.load_state_dict(state_dict)\n",
    "\n",
    "    # Use all 3 scales for computing YOLO loss\n",
    "    YOLO_losses = []\n",
    "    for i in range(3):\n",
    "        YOLO_losses.append(YoloLoss(config['classes'], (config['img_w'], config['img_h']), config['anchors'][i]))\n",
    "\n",
    "    # Check if your system supports CUDA\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "\n",
    "    # Setup GPU optimization if CUDA is supported\n",
    "    if use_cuda:\n",
    "        computing_device = torch.device(\"cuda\")\n",
    "        extras = {\"num_workers\": 3, \"pin_memory\": True}\n",
    "        print(\"CUDA is supported\")\n",
    "    else: # Otherwise, train on the CPU\n",
    "        computing_device = torch.device(\"cpu\")\n",
    "        extras = False\n",
    "        print(\"CUDA NOT supported\")\n",
    "    \n",
    "    # Load in data \n",
    "    root_dir = os.getcwd()\n",
    "    train_dataloader, val_loader, test_loader = create_split_loaders(root_dir=root_dir, batch_size=config['batch_size'])\n",
    "    \n",
    "    # Instantiate model to run on the GPU or CPU based on CUDA support\n",
    "    net = net.to(computing_device)\n",
    "    print(\"Model on CUDA?\", next(net.parameters()).is_cuda)\n",
    "    \n",
    "    # Begin training loop\n",
    "    print(\"Start training:\")\n",
    "    for epoch in range(config['epochs']):\n",
    "        for minibatch, (images, labels) in enumerate(train_dataloader):\n",
    "            start_time = time.time()\n",
    "            print(start_time)\n",
    "            config['global_step'] += 1\n",
    "\n",
    "            # Forward and backward\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss_names = [\"total_loss\", \"x\", \"y\", \"w\", \"h\", \"conf\", \"cls\"]\n",
    "            losses = []\n",
    "            for z in range(len(loss_names)):\n",
    "                losses.append([])\n",
    "            for i in range(3):\n",
    "                loss_item = YOLO_losses[i](outputs[i], labels)\n",
    "                for j, l in enumerate(loss_item):\n",
    "                    losses[j].append(l)\n",
    "            losses = [sum(l) for l in losses]\n",
    "            loss = losses[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if minibatch > 0 and minibatch % 10 == 0:\n",
    "                _loss = loss.item()\n",
    "                lr = optimizer.param_groups[0]['lr']\n",
    "                print('Epoch [%.3d] Minibatch = %d Loss = %.2f lr = %.5f '%\n",
    "                    (epoch, minibatch, _loss, lr)\n",
    "                )\n",
    "                config['tensorboard_writer'].add_scalar(\"lr\",\n",
    "                                                        lr,\n",
    "                                                        config['global_step'])\n",
    "                for i, name in enumerate(loss_names):\n",
    "                    value = _loss if i == 0 else losses[i]\n",
    "                    config['tensorboard_writer'].add_scalar(name,\n",
    "                                                            value,\n",
    "                                                            config['global_step'])\n",
    "\n",
    "            if minbatch > 0 and minibatch % 1000 == 0:\n",
    "                save_checkpoint(net.state_dict(), config)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    save_checkpoint(net.state_dict(), config)\n",
    "    print('Training Complete')\n",
    "\n",
    "    \n",
    "def save_checkpoint(state_dict, config, evaluate_func=None):\n",
    "        \n",
    "    checkpoint_path = os.path.join(config[\"sub_working_dir\"], \"model.pth\")\n",
    "    torch.save(state_dict, checkpoint_path)\n",
    "    print(\"Model checkpoint saved to %s\" % checkpoint_path)\n",
    "\n",
    "\n",
    "def obtain_optimizer(config, net):\n",
    "    optimizer = None\n",
    "\n",
    "    # Assign different learning rate for each layer\n",
    "    params = None\n",
    "    base_parameters = list(\n",
    "        map(id, net.backbone.parameters())\n",
    "    )\n",
    "    logits_parameters = filter(lambda p: id(p) not in base_parameters, net.parameters())\n",
    "\n",
    "    if not config['freeze_backbone']:\n",
    "        parameters = [\n",
    "            {\"params\": logits_parameters, \"lr\": config['other_lr']},\n",
    "            {\"params\": net.backbone.parameters(), \"lr\": config['backbone_lr']},\n",
    "        ]\n",
    "    else:\n",
    "        print(\"Freezing backbone parameters\")\n",
    "        for p in net.backbone.parameters():\n",
    "            p.requires_grad = False\n",
    "        parameters = [\n",
    "            {\"params\": logits_parameters, \"lr\": config['other_lr']},\n",
    "        ]\n",
    "\n",
    "    # Initialize optimizer class\n",
    "    if config['optimizer_type'] == \"adam\":\n",
    "        optimizer = optim.Adam(params, weight_decay=config['optimizer_weight_decay'])\n",
    "    elif config['optimizer_type'] == \"amsgrad\":\n",
    "        optimizer = optim.Adam(params, weight_decay=config['optimizer_weight_decay'], amsgrad=True)\n",
    "    elif config['optimizer_type'] == \"rmsprop\":\n",
    "        optimizer = optim.RMSprop(params, weight_decay=config['optimizer_weight_decay'])\n",
    "    else:\n",
    "        optimizer = optim.SGD(parameters, momentum=0.9, weight_decay=config['optimizer_weight_decay'],\n",
    "                              nesterov=(config['optimizer_type'] == \"nesterov\"))\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # Initialize hyperparameters/variables\n",
    "    config = {}\n",
    "    config['backbone_name'] = \"darknet_53\"\n",
    "    config['backbone_pretrained'] = \"../darknet53_weights_pytorch.pth\" # set empty to disable\n",
    "    \n",
    "    config['anchors'] = [[[116, 90], [156, 198], [373, 326]],\n",
    "                                [[30, 61], [62, 45], [59, 119]],\n",
    "                                [[10, 13], [16, 30], [33, 23]]]\n",
    "    config['classes'] = 20\n",
    "    \n",
    "    config['backbone_lr'] = 0.001\n",
    "    config['other_lr'] = 0.01\n",
    "    config['freeze_backbone'] = False   #  freeze backbone wegiths to finetune\n",
    "    config['decay_gamma'] = 0.1\n",
    "    config['decay_step'] = 20          #  decay lr in every ? epochs\n",
    "    \n",
    "    config['optimizer_type'] = \"sgd\"\n",
    "    config['optimizer_weight_decay'] = 4e-05\n",
    "    \n",
    "    config['batch_size'] = 16  # Number of training samples per batch to be passed to network\n",
    "    config['epochs'] = 50  # Number of epochs to train the model\n",
    "    config['img_h'] = config['img_w'] = 416,\n",
    "    config['seed'] = np.random.seed()\n",
    "    config['working_dir'] = \"./states\"     #  replace with your working dir\n",
    "    config['pretrain_snapshot'] = \"\"       #  load checkpoint\n",
    "    config['try'] = 0,\n",
    "   \n",
    "    \n",
    "    # Create sub_working_dir\n",
    "    sub_working_dir = '{}/{}/size{}x{}_try{}/{}'.format(\n",
    "        config['working_dir'], config['backbone_name'], \n",
    "        config['img_w'], config['img_h'], config['try'],\n",
    "        time.strftime(\"%Y%m%d%H%M%S\", time.localtime()))\n",
    "    if not os.path.exists(sub_working_dir):\n",
    "        os.makedirs(sub_working_dir)\n",
    "    config[\"sub_working_dir\"] = sub_working_dir\n",
    "    logging.info(\"sub working dir: %s\" % sub_working_dir)\n",
    "                                     \n",
    "\n",
    "    # Create tf_summary writer\n",
    "    config[\"tensorboard_writer\"] = SummaryWriter(sub_working_dir)\n",
    "    logging.info(\"Please using 'python -m tensorboard.main --logdir={}'\".format(sub_working_dir))\n",
    "\n",
    "    # Start training\n",
    "    train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torchvision.datasets' has no attribute 'voc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-972361fa1b80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-3743c9ebb596>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-9c3e7630cca9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# Load in data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mroot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_split_loaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Instantiate model to run on the GPU or CPU based on CUDA support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/home-01/41/741/tjwest/Multi-Object-Detection/PASCAL_Dataloader.py\u001b[0m in \u001b[0;36mcreate_split_loaders\u001b[0;34m(root_dir, batch_size, seed, p_val, p_test, shuffle, show_sample, extras)\u001b[0m\n\u001b[1;32m    166\u001b[0m                          ToTensor(), Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPascalVOC2012Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;31m# Dimensions and indices of training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/home-01/41/741/tjwest/Multi-Object-Detection/PASCAL_Dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, transform, root_dir, mode, download)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'trainval'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPascalVOC2012Dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         self.data = VOCDetection(root=root_dir, year='2012', \\\n\u001b[0m\u001b[1;32m     42\u001b[0m                     transform=transform, image_set=mode, download=download)\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torchvision.datasets' has no attribute 'voc'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
