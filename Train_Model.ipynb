{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "import traceback\n",
    "import logging\n",
    "import importlib\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "%matplotlib inline\n",
    "\n",
    "from yolo_model import yoloModel\n",
    "from PASCAL_Dataloader import create_split_loaders\n",
    "from YOLO_Loss import YoloLoss\n",
    "\n",
    "total_loss = defaultdict(dict)\n",
    "avg_minibatch_loss = []\n",
    "avg_valid_loss = []\n",
    "avg_test_loss = defaultdict(dict)\n",
    "_validation_metrics = defaultdict(dict)\n",
    "tot_test_outputs = []\n",
    "tot_test_labels = []\n",
    "\n",
    "log = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    config['global_step'] = config.get('start_step', 0)\n",
    "    is_training = False if config.get('export_onnx') else True\n",
    "\n",
    "    # TODO: Load and initialize network\n",
    "    net = yoloModel(config)\n",
    "\n",
    "    # Define the optimizer and learning rate\n",
    "    optimizer = obtain_optimizer(config, net)\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer,\n",
    "        step_size=config['decay_step'],\n",
    "        gamma=config['decay_gamma'])\n",
    "\n",
    "    # Use pretrained model\n",
    "    if config['pretrain_snapshot']:\n",
    "        logging.info('Load pretrained weights from {}'.format(config['pretrain_snapshot']))\n",
    "        state_dict = torch.load(config['pretrain_snapshot'])\n",
    "        net.load_state_dict(state_dict)\n",
    "\n",
    "    # Use all 3 scales for computing YOLO loss\n",
    "    YOLO_losses = []\n",
    "    val_YOLO_losses = []\n",
    "    test_YOLO_losses = []\n",
    "    for i in range(3):\n",
    "        YOLO_losses.append(YoloLoss(config['classes'], (config['img_w'], config['img_h']), config['anchors'][i]))\n",
    "        val_YOLO_losses.append(YoloLoss(config['classes'], (config['img_w'], config['img_h']), config['anchors'][i]))\n",
    "        test_YOLO_losses.append(YoloLoss(config['classes'], (config['img_w'], config['img_h']), config['anchors'][i]))\n",
    "\n",
    "    # Check if your system supports CUDA\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "\n",
    "    # Setup GPU optimization if CUDA is supported\n",
    "    if use_cuda:\n",
    "        computing_device = torch.device(\"cuda\")\n",
    "        extras = {\"num_workers\": 3, \"pin_memory\": True}\n",
    "        print(\"CUDA is supported\")\n",
    "    else: # Otherwise, train on the CPU\n",
    "        computing_device = torch.device(\"cpu\")\n",
    "        extras = False\n",
    "        print(\"CUDA NOT supported\")\n",
    "    \n",
    "    # Load in data \n",
    "    root_dir = os.getcwd()\n",
    "    train_loader, val_loader, test_loader = create_split_loaders(root_dir, config['batch_size'])\n",
    "    \n",
    "    # Instantiate model to run on the GPU or CPU based on CUDA support\n",
    "    net = net.to(computing_device)\n",
    "    print(\"Model on CUDA?\", next(net.parameters()).is_cuda)\n",
    "    \n",
    "    # Begin training loop\n",
    "    print(\"Start training:\")\n",
    "    for epoch in range(config['epochs']):\n",
    "        N_minibatch_loss = 0.0\n",
    "        for minibatch, samples in enumerate(train_loader):\n",
    "            images, labels = samples[\"image\"], samples[\"label\"]\n",
    "            #print(labels)\n",
    "            start_time = time.time()\n",
    "            config['global_step'] += 1\n",
    "                \n",
    "            #images = images.unsqueeze(0)\n",
    "\n",
    "            # Put the minibatch data in CUDA Tensors and run on the GPU if supported\n",
    "            images = images.to(computing_device)\n",
    "            #labels = labels.to(computing_device)\n",
    "\n",
    "            # Forward and backward\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            #print(outputs.shape)\n",
    "            loss_names = [\"total_loss\", \"x\", \"y\", \"w\", \"h\", \"conf\", \"cls\"]\n",
    "            losses = []\n",
    "            for z in range(len(loss_names)):\n",
    "                losses.append([])\n",
    "            for i in range(3):\n",
    "                loss_item = YOLO_losses[i](outputs[i], labels)\n",
    "                for j, l in enumerate(loss_item):\n",
    "                    losses[j].append(l)\n",
    "            losses = [sum(l) for l in losses]\n",
    "            loss = losses[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Add this iteration's loss to the total_loss\n",
    "            total_loss[epoch][minibatch] = loss.item()\n",
    "            N_minibatch_loss += loss\n",
    "\n",
    "            if minibatch > 0 and minibatch % 10 == 0:\n",
    "                _loss = loss.item()\n",
    "                N_minibatch_loss /= 10\n",
    "                lr = optimizer.param_groups[0]['lr']\n",
    "                logging.info('Epoch [%.3d] Minibatch = %d Loss = %.2f lr = %.5f '%\n",
    "                    (epoch, minibatch, N_minibatch_loss, lr))\n",
    "                print('Epoch [%.3d] Minibatch = %d Loss = %.2f lr = %.5f '%\n",
    "                    (epoch, minibatch, N_minibatch_loss, lr))\n",
    "                \n",
    "                # Add the averaged loss over N minibatches and reset the counter\n",
    "                avg_minibatch_loss.append(N_minibatch_loss.item())\n",
    "                N_minibatch_loss = 0.0\n",
    "                \n",
    "                config['tensorboard_writer'].add_scalar(\"lr\",\n",
    "                                                        lr,\n",
    "                                                        config['global_step'])\n",
    "                for i, name in enumerate(loss_names):\n",
    "                    value = _loss if i == 0 else losses[i]\n",
    "                    config['tensorboard_writer'].add_scalar(name,\n",
    "                                                            value,\n",
    "                                                            config['global_step'])\n",
    "\n",
    "            if epoch==0 and minibatch % 205 == 0:\n",
    "                save_checkpoint(net.state_dict(), config)\n",
    "                \n",
    "                # Implement cross-validation\n",
    "                val_loss = 0\n",
    "                sum_val_loss = 0\n",
    "                validation_outputs = []\n",
    "                validation_labels = []\n",
    "                with torch.no_grad():\n",
    "                    for valid_batch_count, samples in enumerate(val_loader):\n",
    "                        val_images, val_labels = samples[\"image\"], samples[\"label\"]\n",
    "                        val_images = val_images.to(computing_device)\n",
    "                        val_outputs = net(val_images)\n",
    "                        val_losses = []\n",
    "                        for z in range(len(loss_names)):\n",
    "                            val_losses.append([])\n",
    "                        for i in range(3):\n",
    "                            val_loss_item = val_YOLO_losses[i](val_outputs[i], val_labels)\n",
    "                            for j, l in enumerate(val_loss_item):\n",
    "                                val_losses[j].append(l)\n",
    "                        val_losses = [sum(l) for l in val_losses]\n",
    "                        val_loss = val_losses[0]\n",
    "                        sum_val_loss += val_loss\n",
    "                        print(\"\\tvalid_batch_count: \", valid_batch_count)\n",
    "                        '''\n",
    "                        for v in val_outputs.data.tolist():\n",
    "                            validation_outputs.append(v)\n",
    "                        for l in val_labels.data.tolist():\n",
    "                            validation_labels.append(l)\n",
    "                        '''\n",
    "\n",
    "                    sum_val_loss /= len(val_loader)\n",
    "                    print(\"avg validation loss: \", sum_val_loss)\n",
    "                    avg_valid_loss.append(sum_val_loss.item())\n",
    "                    #_validation_metrics[epoch][minibatch_count] = metrics(validation_outputs, validation_labels, _threshold)\n",
    "\n",
    "            if epoch > 0 and minibatch > 0 and minibatch % 205 == 0:\n",
    "                save_checkpoint(net.state_dict(), config)\n",
    "                \n",
    "                # Implement cross-validation\n",
    "                val_loss = 0\n",
    "                sum_val_loss = 0\n",
    "                validation_outputs = []\n",
    "                validation_labels = []\n",
    "                with torch.no_grad():\n",
    "                    for valid_batch_count, samples in enumerate(val_loader):\n",
    "                        val_images, val_labels = samples[\"image\"], samples[\"label\"]\n",
    "                        val_images = val_images.to(computing_device)\n",
    "                        val_outputs = net(val_images)\n",
    "                        val_losses = []\n",
    "                        for z in range(len(loss_names)):\n",
    "                            val_losses.append([])\n",
    "                        for i in range(3):\n",
    "                            val_loss_item = val_YOLO_losses[i](val_outputs[i], val_labels)\n",
    "                            for j, l in enumerate(val_loss_item):\n",
    "                                val_losses[j].append(l)\n",
    "                        val_losses = [sum(l) for l in val_losses]\n",
    "                        val_loss = val_losses[0]\n",
    "                        sum_val_loss += val_loss\n",
    "                        print(\"\\tvalid_batch_count: \", valid_batch_count)\n",
    "                        '''\n",
    "                        for v in val_outputs.data.tolist():\n",
    "                            validation_outputs.append(v)\n",
    "                        for l in val_labels.data.tolist():\n",
    "                            validation_labels.append(l)\n",
    "                        '''\n",
    "\n",
    "                    sum_val_loss /= len(val_loader)\n",
    "                    print(\"avg validation loss: \", sum_val_loss)\n",
    "                    avg_valid_loss.append(sum_val_loss.item())\n",
    "                    \n",
    "        lr_scheduler.step()\n",
    "\n",
    "    save_checkpoint(net.state_dict(), config)\n",
    "    print('Training Complete')\n",
    "    \n",
    "    test_loss = 0\n",
    "    sum_test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for test_batch_count, samples in enumerate(test_loader):\n",
    "            test_images, test_labels = samples[\"image\"], samples[\"label\"]\n",
    "            print(\"\\ttest_batch_count: \", test_batch_count)\n",
    "            test_images= test_images.to(computing_device)\n",
    "            test_outputs = net(test_images)\n",
    "            test_losses = []\n",
    "            for z in range(len(loss_names)):\n",
    "                test_losses.append([])\n",
    "            for i in range(3):\n",
    "                test_loss_item = test_YOLO_losses[i](test_outputs[i], test_labels)\n",
    "                for j, l in enumerate(val_loss_item):\n",
    "                    test_losses[j].append(l)\n",
    "            test_losses = [sum(l) for l in test_losses]\n",
    "            test_loss = test_losses[0]\n",
    "            sum_test_loss += test_loss\n",
    "            '''\n",
    "            for o in test_outputs:\n",
    "                tot_test_outputs.append([d.item() for d in o.data])\n",
    "            for l in test_labels:\n",
    "                tot_test_labels.append([d.item() for d in l.data])\n",
    "            '''\n",
    "        sum_test_loss /= len(test_loader)\n",
    "        print(\"avg test loss: \", sum_test_loss)\n",
    "        avg_test_loss[epoch] = test_loss.item()\n",
    "    \n",
    "    return avg_minibatch_loss, avg_valid_loss\n",
    "\n",
    "    \n",
    "def save_checkpoint(state_dict, config, evaluate_func=None):\n",
    "        \n",
    "    checkpoint_path = os.path.join(config[\"sub_working_dir\"], \"model.pth\")\n",
    "    torch.save(state_dict, checkpoint_path)\n",
    "    logging.info(\"Model checkpoint saved to %s\" % checkpoint_path)\n",
    "\n",
    "\n",
    "def obtain_optimizer(config, net):\n",
    "    optimizer = None\n",
    "\n",
    "    # Assign different learning rate for each layer\n",
    "    params = None\n",
    "    base_parameters = list(\n",
    "        map(id, net.backbone.parameters())\n",
    "    )\n",
    "    logits_parameters = filter(lambda p: id(p) not in base_parameters, net.parameters())\n",
    "\n",
    "    if not config['freeze_backbone']:\n",
    "        parameters = [\n",
    "            {\"params\": logits_parameters, \"lr\": config['other_lr']},\n",
    "            {\"params\": net.backbone.parameters(), \"lr\": config['backbone_lr']},\n",
    "        ]\n",
    "    else:\n",
    "        print(\"Freezing backbone parameters\")\n",
    "        for p in net.backbone.parameters():\n",
    "            p.requires_grad = False\n",
    "        parameters = [\n",
    "            {\"params\": logits_parameters, \"lr\": config['other_lr']},\n",
    "        ]\n",
    "\n",
    "    # Initialize optimizer class\n",
    "    if config['optimizer_type'] == \"adam\":\n",
    "        optimizer = optim.Adam(params, weight_decay=config['optimizer_weight_decay'])\n",
    "    elif config['optimizer_type'] == \"amsgrad\":\n",
    "        optimizer = optim.Adam(params, weight_decay=config['optimizer_weight_decay'], amsgrad=True)\n",
    "    elif config['optimizer_type'] == \"rmsprop\":\n",
    "        optimizer = optim.RMSprop(params, weight_decay=config['optimizer_weight_decay'])\n",
    "    else:\n",
    "        optimizer = optim.SGD(parameters, momentum=0.9, weight_decay=config['optimizer_weight_decay'],\n",
    "                              nesterov=(config['optimizer_type'] == \"nesterov\"))\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(arch=None, init=None, optim=None, output_file=None):\n",
    "    \n",
    "    '''\n",
    "    if arch is None:\n",
    "        if len(sys.argv) < 4 or len(sys.argv) > 5:\n",
    "            print(\"Usage: python3 daemon.py <arch> <init> <optim> [output_filename]\")\n",
    "            return -1\n",
    "        if len(sys.argv) >= 4:\n",
    "            arch = sys.argv[1]\n",
    "            init = sys.argv[2]\n",
    "            optim = sys.argv[3]\n",
    "        if len(sys.argv) >= 5:\n",
    "            output_file = sys.argv[4]\n",
    "    '''\n",
    "    if output_file is None:\n",
    "        output_file = \"_\".join([str(datetime.now().strftime(\"%Y%m%d-%H%M%S\"))]) + \".json\"\n",
    "        print(output_file)\n",
    "        \n",
    "    log['data'] = {\n",
    "        'total_loss': total_loss,\n",
    "        'avg_minibatch_loss': avg_minibatch_loss,\n",
    "        'avg_valid_loss': avg_valid_loss,\n",
    "        'validation_metrics': _validation_metrics,\n",
    "        'test_outputs': tot_test_outputs,\n",
    "        'test_labels': tot_test_labels\n",
    "    }\n",
    "        \n",
    "    with open(\"logs/\" + output_file, 'w') as f:\n",
    "        json.dump(log, f, indent=4)\n",
    "    \n",
    "    # Initialize hyperparameters/variables\n",
    "    config = {}\n",
    "    config['backbone_name'] = \"darknet_53\"\n",
    "    config['backbone_pretrained'] = \"./darknet53_weights_pytorch.pth\" # set empty to disable\n",
    "    \n",
    "    config['anchors'] = [[[116, 90], [156, 198], [373, 326]],\n",
    "                                [[30, 61], [62, 45], [59, 119]],\n",
    "                                [[10, 13], [16, 30], [33, 23]]]\n",
    "    config['classes'] = 20\n",
    "    \n",
    "    config['backbone_lr'] = 0.001\n",
    "    config['other_lr'] = 0.01\n",
    "    config['freeze_backbone'] = False   #  freeze backbone wegiths to finetune\n",
    "    config['decay_gamma'] = 0.5\n",
    "    config['decay_step'] = 6         #  decay lr in every ? epochs\n",
    "    \n",
    "    config['optimizer_type'] = \"sgd\"\n",
    "    config['optimizer_weight_decay'] = 4e-05\n",
    "    \n",
    "    config['batch_size'] = 20  # Number of training samples per batch to be passed to network\n",
    "    config['epochs'] = 10  # Number of epochs to train the model\n",
    "    config['img_h'] = config['img_w'] = 416\n",
    "    config['seed'] = np.random.seed()\n",
    "    config['working_dir'] = \"./states\"     #  replace with your working dir\n",
    "    \n",
    "    def get_latest_states(dirpath):\n",
    "        \"\"\"\n",
    "        Get the latest image file in the given directory\n",
    "        \"\"\"\n",
    "        # get filepaths of all files and dirs in the given dir\n",
    "        valid_files = [os.path.join(dirpath, filename) for filename in os.listdir(dirpath)]\n",
    "\n",
    "        return max(valid_files, key=os.path.getmtime)\n",
    "   \n",
    "    \n",
    "    # Create sub_working_dir\n",
    "    sub_working_dir = '{}/{}'.format(\n",
    "        config['working_dir'], time.strftime(\"%Y%m%d%H%M%S\", time.localtime()))\n",
    "    #if not os.path.exists(sub_working_dir):\n",
    "        #os.makedirs(sub_working_dir)\n",
    "    config[\"sub_working_dir\"] = sub_working_dir\n",
    "    logging.info(\"sub working dir: %s\" % sub_working_dir)\n",
    "    \n",
    "    if not os.path.exists(os.path.join(sub_working_dir, \"model.pth\")):\n",
    "        config['pretrain_snapshot'] = \"\"\n",
    "    else:\n",
    "        config['pretrain_snapshot'] = os.path.join(get_latest_states(config['working_dir']), \"model.pth\")  # load checkpoint\n",
    "        \n",
    "    # Create tf_summary writer\n",
    "    config[\"tensorboard_writer\"] = SummaryWriter(sub_working_dir)\n",
    "\n",
    "    # Start training\n",
    "    train_loss, valid_loss = train(config)\n",
    "    \n",
    "    return train_loss, valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20190530-222509.json\n",
      "CUDA is supported\n",
      "Model on CUDA? True\n",
      "Start training:\n",
      "\tvalid_batch_count:  0\n",
      "\tvalid_batch_count:  1\n",
      "\tvalid_batch_count:  2\n",
      "\tvalid_batch_count:  3\n",
      "\tvalid_batch_count:  4\n",
      "\tvalid_batch_count:  5\n",
      "\tvalid_batch_count:  6\n",
      "\tvalid_batch_count:  7\n",
      "\tvalid_batch_count:  8\n",
      "\tvalid_batch_count:  9\n",
      "\tvalid_batch_count:  10\n",
      "\tvalid_batch_count:  11\n",
      "\tvalid_batch_count:  12\n",
      "\tvalid_batch_count:  13\n",
      "\tvalid_batch_count:  14\n",
      "\tvalid_batch_count:  15\n",
      "\tvalid_batch_count:  16\n",
      "\tvalid_batch_count:  17\n",
      "\tvalid_batch_count:  18\n",
      "\tvalid_batch_count:  19\n",
      "\tvalid_batch_count:  20\n",
      "\tvalid_batch_count:  21\n",
      "\tvalid_batch_count:  22\n",
      "\tvalid_batch_count:  23\n",
      "\tvalid_batch_count:  24\n",
      "\tvalid_batch_count:  25\n",
      "\tvalid_batch_count:  26\n",
      "\tvalid_batch_count:  27\n",
      "\tvalid_batch_count:  28\n",
      "\tvalid_batch_count:  29\n",
      "\tvalid_batch_count:  30\n",
      "\tvalid_batch_count:  31\n",
      "\tvalid_batch_count:  32\n",
      "\tvalid_batch_count:  33\n",
      "\tvalid_batch_count:  34\n",
      "\tvalid_batch_count:  35\n",
      "\tvalid_batch_count:  36\n",
      "\tvalid_batch_count:  37\n",
      "\tvalid_batch_count:  38\n",
      "\tvalid_batch_count:  39\n",
      "\tvalid_batch_count:  40\n",
      "\tvalid_batch_count:  41\n",
      "\tvalid_batch_count:  42\n",
      "\tvalid_batch_count:  43\n",
      "\tvalid_batch_count:  44\n",
      "\tvalid_batch_count:  45\n",
      "\tvalid_batch_count:  46\n",
      "\tvalid_batch_count:  47\n",
      "\tvalid_batch_count:  48\n",
      "\tvalid_batch_count:  49\n",
      "\tvalid_batch_count:  50\n",
      "\tvalid_batch_count:  51\n",
      "\tvalid_batch_count:  52\n",
      "\tvalid_batch_count:  53\n",
      "\tvalid_batch_count:  54\n",
      "\tvalid_batch_count:  55\n",
      "\tvalid_batch_count:  56\n",
      "\tvalid_batch_count:  57\n",
      "avg validation loss:  tensor(3.2072, device='cuda:0')\n",
      "Epoch [000] Minibatch = 10 Loss = 3.14 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 20 Loss = 1.76 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 30 Loss = 1.14 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 40 Loss = 0.86 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 50 Loss = 0.75 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 60 Loss = 0.67 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 70 Loss = 0.65 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 80 Loss = 0.63 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 90 Loss = 0.57 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 100 Loss = 0.60 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 110 Loss = 0.54 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 120 Loss = 0.52 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 130 Loss = 0.50 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 140 Loss = 0.47 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 150 Loss = 0.46 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 160 Loss = 0.49 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 170 Loss = 0.48 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 180 Loss = 0.46 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 190 Loss = 0.41 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 200 Loss = 0.42 lr = 0.01000 \n",
      "\tvalid_batch_count:  0\n",
      "\tvalid_batch_count:  1\n",
      "\tvalid_batch_count:  2\n",
      "\tvalid_batch_count:  3\n",
      "\tvalid_batch_count:  4\n",
      "\tvalid_batch_count:  5\n",
      "\tvalid_batch_count:  6\n",
      "\tvalid_batch_count:  7\n",
      "\tvalid_batch_count:  8\n",
      "\tvalid_batch_count:  9\n",
      "\tvalid_batch_count:  10\n",
      "\tvalid_batch_count:  11\n",
      "\tvalid_batch_count:  12\n",
      "\tvalid_batch_count:  13\n",
      "\tvalid_batch_count:  14\n",
      "\tvalid_batch_count:  15\n",
      "\tvalid_batch_count:  16\n",
      "\tvalid_batch_count:  17\n",
      "\tvalid_batch_count:  18\n",
      "\tvalid_batch_count:  19\n",
      "\tvalid_batch_count:  20\n",
      "\tvalid_batch_count:  21\n",
      "\tvalid_batch_count:  22\n",
      "\tvalid_batch_count:  23\n",
      "\tvalid_batch_count:  24\n",
      "\tvalid_batch_count:  25\n",
      "\tvalid_batch_count:  26\n",
      "\tvalid_batch_count:  27\n",
      "\tvalid_batch_count:  28\n",
      "\tvalid_batch_count:  29\n",
      "\tvalid_batch_count:  30\n",
      "\tvalid_batch_count:  31\n",
      "\tvalid_batch_count:  32\n",
      "\tvalid_batch_count:  33\n",
      "\tvalid_batch_count:  34\n",
      "\tvalid_batch_count:  35\n",
      "\tvalid_batch_count:  36\n",
      "\tvalid_batch_count:  37\n",
      "\tvalid_batch_count:  38\n",
      "\tvalid_batch_count:  39\n",
      "\tvalid_batch_count:  40\n",
      "\tvalid_batch_count:  41\n",
      "\tvalid_batch_count:  42\n",
      "\tvalid_batch_count:  43\n",
      "\tvalid_batch_count:  44\n",
      "\tvalid_batch_count:  45\n",
      "\tvalid_batch_count:  46\n",
      "\tvalid_batch_count:  47\n",
      "\tvalid_batch_count:  48\n",
      "\tvalid_batch_count:  49\n",
      "\tvalid_batch_count:  50\n",
      "\tvalid_batch_count:  51\n",
      "\tvalid_batch_count:  52\n",
      "\tvalid_batch_count:  53\n",
      "\tvalid_batch_count:  54\n",
      "\tvalid_batch_count:  55\n",
      "\tvalid_batch_count:  56\n",
      "\tvalid_batch_count:  57\n",
      "avg validation loss:  tensor(0.4168, device='cuda:0')\n",
      "Epoch [000] Minibatch = 210 Loss = 0.41 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 220 Loss = 0.44 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 230 Loss = 0.40 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 240 Loss = 0.41 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 250 Loss = 0.39 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 260 Loss = 0.39 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 270 Loss = 0.38 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 280 Loss = 0.36 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 290 Loss = 0.36 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 300 Loss = 0.35 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 310 Loss = 0.35 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 320 Loss = 0.37 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 330 Loss = 0.33 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 340 Loss = 0.35 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 350 Loss = 0.33 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 360 Loss = 0.31 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 370 Loss = 0.30 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 380 Loss = 0.31 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 390 Loss = 0.30 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 400 Loss = 0.31 lr = 0.01000 \n",
      "Epoch [000] Minibatch = 410 Loss = 0.27 lr = 0.01000 \n",
      "\tvalid_batch_count:  0\n",
      "\tvalid_batch_count:  1\n",
      "\tvalid_batch_count:  2\n",
      "\tvalid_batch_count:  3\n",
      "\tvalid_batch_count:  4\n",
      "\tvalid_batch_count:  5\n",
      "\tvalid_batch_count:  6\n",
      "\tvalid_batch_count:  7\n",
      "\tvalid_batch_count:  8\n",
      "\tvalid_batch_count:  9\n",
      "\tvalid_batch_count:  10\n",
      "\tvalid_batch_count:  11\n",
      "\tvalid_batch_count:  12\n",
      "\tvalid_batch_count:  13\n",
      "\tvalid_batch_count:  14\n",
      "\tvalid_batch_count:  15\n",
      "\tvalid_batch_count:  16\n",
      "\tvalid_batch_count:  17\n",
      "\tvalid_batch_count:  18\n",
      "\tvalid_batch_count:  19\n",
      "\tvalid_batch_count:  20\n",
      "\tvalid_batch_count:  21\n",
      "\tvalid_batch_count:  22\n",
      "\tvalid_batch_count:  23\n",
      "\tvalid_batch_count:  24\n",
      "\tvalid_batch_count:  25\n",
      "\tvalid_batch_count:  26\n",
      "\tvalid_batch_count:  27\n",
      "\tvalid_batch_count:  28\n",
      "\tvalid_batch_count:  29\n",
      "\tvalid_batch_count:  30\n",
      "\tvalid_batch_count:  31\n",
      "\tvalid_batch_count:  32\n",
      "\tvalid_batch_count:  33\n",
      "\tvalid_batch_count:  34\n",
      "\tvalid_batch_count:  35\n",
      "\tvalid_batch_count:  36\n",
      "\tvalid_batch_count:  37\n",
      "\tvalid_batch_count:  38\n",
      "\tvalid_batch_count:  39\n",
      "\tvalid_batch_count:  40\n",
      "\tvalid_batch_count:  41\n",
      "\tvalid_batch_count:  42\n",
      "\tvalid_batch_count:  43\n",
      "\tvalid_batch_count:  44\n",
      "\tvalid_batch_count:  45\n",
      "\tvalid_batch_count:  46\n",
      "\tvalid_batch_count:  47\n",
      "\tvalid_batch_count:  48\n",
      "\tvalid_batch_count:  49\n",
      "\tvalid_batch_count:  50\n",
      "\tvalid_batch_count:  51\n",
      "\tvalid_batch_count:  52\n",
      "\tvalid_batch_count:  53\n",
      "\tvalid_batch_count:  54\n",
      "\tvalid_batch_count:  55\n",
      "\tvalid_batch_count:  56\n",
      "\tvalid_batch_count:  57\n",
      "avg validation loss:  tensor(0.2978, device='cuda:0')\n",
      "Epoch [001] Minibatch = 10 Loss = 0.31 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 20 Loss = 0.26 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 30 Loss = 0.26 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 40 Loss = 0.25 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 50 Loss = 0.28 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 60 Loss = 0.24 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 70 Loss = 0.25 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 80 Loss = 0.26 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 90 Loss = 0.24 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 100 Loss = 0.24 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 110 Loss = 0.24 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 120 Loss = 0.24 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 130 Loss = 0.25 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 140 Loss = 0.23 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 150 Loss = 0.24 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 160 Loss = 0.24 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 170 Loss = 0.24 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 180 Loss = 0.22 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 190 Loss = 0.23 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 200 Loss = 0.22 lr = 0.01000 \n",
      "\tvalid_batch_count:  0\n",
      "\tvalid_batch_count:  1\n",
      "\tvalid_batch_count:  2\n",
      "\tvalid_batch_count:  3\n",
      "\tvalid_batch_count:  4\n",
      "\tvalid_batch_count:  5\n",
      "\tvalid_batch_count:  6\n",
      "\tvalid_batch_count:  7\n",
      "\tvalid_batch_count:  8\n",
      "\tvalid_batch_count:  9\n",
      "\tvalid_batch_count:  10\n",
      "\tvalid_batch_count:  11\n",
      "\tvalid_batch_count:  12\n",
      "\tvalid_batch_count:  13\n",
      "\tvalid_batch_count:  14\n",
      "\tvalid_batch_count:  15\n",
      "\tvalid_batch_count:  16\n",
      "\tvalid_batch_count:  17\n",
      "\tvalid_batch_count:  18\n",
      "\tvalid_batch_count:  19\n",
      "\tvalid_batch_count:  20\n",
      "\tvalid_batch_count:  21\n",
      "\tvalid_batch_count:  22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalid_batch_count:  23\n",
      "\tvalid_batch_count:  24\n",
      "\tvalid_batch_count:  25\n",
      "\tvalid_batch_count:  26\n",
      "\tvalid_batch_count:  27\n",
      "\tvalid_batch_count:  28\n",
      "\tvalid_batch_count:  29\n",
      "\tvalid_batch_count:  30\n",
      "\tvalid_batch_count:  31\n",
      "\tvalid_batch_count:  32\n",
      "\tvalid_batch_count:  33\n",
      "\tvalid_batch_count:  34\n",
      "\tvalid_batch_count:  35\n",
      "\tvalid_batch_count:  36\n",
      "\tvalid_batch_count:  37\n",
      "\tvalid_batch_count:  38\n",
      "\tvalid_batch_count:  39\n",
      "\tvalid_batch_count:  40\n",
      "\tvalid_batch_count:  41\n",
      "\tvalid_batch_count:  42\n",
      "\tvalid_batch_count:  43\n",
      "\tvalid_batch_count:  44\n",
      "\tvalid_batch_count:  45\n",
      "\tvalid_batch_count:  46\n",
      "\tvalid_batch_count:  47\n",
      "\tvalid_batch_count:  48\n",
      "\tvalid_batch_count:  49\n",
      "\tvalid_batch_count:  50\n",
      "\tvalid_batch_count:  51\n",
      "\tvalid_batch_count:  52\n",
      "\tvalid_batch_count:  53\n",
      "\tvalid_batch_count:  54\n",
      "\tvalid_batch_count:  55\n",
      "\tvalid_batch_count:  56\n",
      "\tvalid_batch_count:  57\n",
      "avg validation loss:  tensor(0.2370, device='cuda:0')\n",
      "Epoch [001] Minibatch = 210 Loss = 0.23 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 220 Loss = 0.22 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 230 Loss = 0.20 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 240 Loss = 0.24 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 250 Loss = 0.21 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 260 Loss = 0.22 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 270 Loss = 0.20 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 280 Loss = 0.24 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 290 Loss = 0.19 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 300 Loss = 0.21 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 310 Loss = 0.19 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 320 Loss = 0.18 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 330 Loss = 0.19 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 340 Loss = 0.23 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 350 Loss = 0.21 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 360 Loss = 0.21 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 370 Loss = 0.20 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 380 Loss = 0.19 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 390 Loss = 0.20 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 400 Loss = 0.19 lr = 0.01000 \n",
      "Epoch [001] Minibatch = 410 Loss = 0.19 lr = 0.01000 \n",
      "\tvalid_batch_count:  0\n",
      "\tvalid_batch_count:  1\n",
      "\tvalid_batch_count:  2\n",
      "\tvalid_batch_count:  3\n",
      "\tvalid_batch_count:  4\n",
      "\tvalid_batch_count:  5\n",
      "\tvalid_batch_count:  6\n",
      "\tvalid_batch_count:  7\n",
      "\tvalid_batch_count:  8\n",
      "\tvalid_batch_count:  9\n",
      "\tvalid_batch_count:  10\n",
      "\tvalid_batch_count:  11\n",
      "\tvalid_batch_count:  12\n",
      "\tvalid_batch_count:  13\n",
      "\tvalid_batch_count:  14\n",
      "\tvalid_batch_count:  15\n",
      "\tvalid_batch_count:  16\n",
      "\tvalid_batch_count:  17\n",
      "\tvalid_batch_count:  18\n",
      "\tvalid_batch_count:  19\n",
      "\tvalid_batch_count:  20\n",
      "\tvalid_batch_count:  21\n",
      "\tvalid_batch_count:  22\n",
      "\tvalid_batch_count:  23\n",
      "\tvalid_batch_count:  24\n",
      "\tvalid_batch_count:  25\n",
      "\tvalid_batch_count:  26\n",
      "\tvalid_batch_count:  27\n",
      "\tvalid_batch_count:  28\n",
      "\tvalid_batch_count:  29\n",
      "\tvalid_batch_count:  30\n",
      "\tvalid_batch_count:  31\n",
      "\tvalid_batch_count:  32\n",
      "\tvalid_batch_count:  33\n",
      "\tvalid_batch_count:  34\n",
      "\tvalid_batch_count:  35\n",
      "\tvalid_batch_count:  36\n",
      "\tvalid_batch_count:  37\n",
      "\tvalid_batch_count:  38\n",
      "\tvalid_batch_count:  39\n",
      "\tvalid_batch_count:  40\n",
      "\tvalid_batch_count:  41\n",
      "\tvalid_batch_count:  42\n",
      "\tvalid_batch_count:  43\n",
      "\tvalid_batch_count:  44\n",
      "\tvalid_batch_count:  45\n",
      "\tvalid_batch_count:  46\n",
      "\tvalid_batch_count:  47\n",
      "\tvalid_batch_count:  48\n",
      "\tvalid_batch_count:  49\n",
      "\tvalid_batch_count:  50\n",
      "\tvalid_batch_count:  51\n",
      "\tvalid_batch_count:  52\n",
      "\tvalid_batch_count:  53\n",
      "\tvalid_batch_count:  54\n",
      "\tvalid_batch_count:  55\n",
      "\tvalid_batch_count:  56\n",
      "\tvalid_batch_count:  57\n",
      "avg validation loss:  tensor(0.2098, device='cuda:0')\n",
      "Epoch [002] Minibatch = 10 Loss = 0.19 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 20 Loss = 0.18 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 30 Loss = 0.17 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 40 Loss = 0.16 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 50 Loss = 0.16 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 60 Loss = 0.17 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 70 Loss = 0.19 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 80 Loss = 0.15 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 90 Loss = 0.16 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 100 Loss = 0.16 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 110 Loss = 0.15 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 120 Loss = 0.16 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 130 Loss = 0.15 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 140 Loss = 0.16 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 150 Loss = 0.17 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 160 Loss = 0.17 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 170 Loss = 0.18 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 180 Loss = 0.17 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 190 Loss = 0.14 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 200 Loss = 0.16 lr = 0.01000 \n",
      "\tvalid_batch_count:  0\n",
      "\tvalid_batch_count:  1\n",
      "\tvalid_batch_count:  2\n",
      "\tvalid_batch_count:  3\n",
      "\tvalid_batch_count:  4\n",
      "\tvalid_batch_count:  5\n",
      "\tvalid_batch_count:  6\n",
      "\tvalid_batch_count:  7\n",
      "\tvalid_batch_count:  8\n",
      "\tvalid_batch_count:  9\n",
      "\tvalid_batch_count:  10\n",
      "\tvalid_batch_count:  11\n",
      "\tvalid_batch_count:  12\n",
      "\tvalid_batch_count:  13\n",
      "\tvalid_batch_count:  14\n",
      "\tvalid_batch_count:  15\n",
      "\tvalid_batch_count:  16\n",
      "\tvalid_batch_count:  17\n",
      "\tvalid_batch_count:  18\n",
      "\tvalid_batch_count:  19\n",
      "\tvalid_batch_count:  20\n",
      "\tvalid_batch_count:  21\n",
      "\tvalid_batch_count:  22\n",
      "\tvalid_batch_count:  23\n",
      "\tvalid_batch_count:  24\n",
      "\tvalid_batch_count:  25\n",
      "\tvalid_batch_count:  26\n",
      "\tvalid_batch_count:  27\n",
      "\tvalid_batch_count:  28\n",
      "\tvalid_batch_count:  29\n",
      "\tvalid_batch_count:  30\n",
      "\tvalid_batch_count:  31\n",
      "\tvalid_batch_count:  32\n",
      "\tvalid_batch_count:  33\n",
      "\tvalid_batch_count:  34\n",
      "\tvalid_batch_count:  35\n",
      "\tvalid_batch_count:  36\n",
      "\tvalid_batch_count:  37\n",
      "\tvalid_batch_count:  38\n",
      "\tvalid_batch_count:  39\n",
      "\tvalid_batch_count:  40\n",
      "\tvalid_batch_count:  41\n",
      "\tvalid_batch_count:  42\n",
      "\tvalid_batch_count:  43\n",
      "\tvalid_batch_count:  44\n",
      "\tvalid_batch_count:  45\n",
      "\tvalid_batch_count:  46\n",
      "\tvalid_batch_count:  47\n",
      "\tvalid_batch_count:  48\n",
      "\tvalid_batch_count:  49\n",
      "\tvalid_batch_count:  50\n",
      "\tvalid_batch_count:  51\n",
      "\tvalid_batch_count:  52\n",
      "\tvalid_batch_count:  53\n",
      "\tvalid_batch_count:  54\n",
      "\tvalid_batch_count:  55\n",
      "\tvalid_batch_count:  56\n",
      "\tvalid_batch_count:  57\n",
      "avg validation loss:  tensor(0.1917, device='cuda:0')\n",
      "Epoch [002] Minibatch = 210 Loss = 0.16 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 220 Loss = 0.15 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 230 Loss = 0.17 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 240 Loss = 0.16 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 250 Loss = 0.18 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 260 Loss = 0.14 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 270 Loss = 0.15 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 280 Loss = 0.14 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 290 Loss = 0.16 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 300 Loss = 0.15 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 310 Loss = 0.15 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 320 Loss = 0.15 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 330 Loss = 0.16 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 340 Loss = 0.14 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 350 Loss = 0.15 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 360 Loss = 0.15 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 370 Loss = 0.16 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 380 Loss = 0.16 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 390 Loss = 0.15 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 400 Loss = 0.14 lr = 0.01000 \n",
      "Epoch [002] Minibatch = 410 Loss = 0.15 lr = 0.01000 \n",
      "\tvalid_batch_count:  0\n",
      "\tvalid_batch_count:  1\n",
      "\tvalid_batch_count:  2\n",
      "\tvalid_batch_count:  3\n",
      "\tvalid_batch_count:  4\n",
      "\tvalid_batch_count:  5\n",
      "\tvalid_batch_count:  6\n",
      "\tvalid_batch_count:  7\n",
      "\tvalid_batch_count:  8\n",
      "\tvalid_batch_count:  9\n",
      "\tvalid_batch_count:  10\n",
      "\tvalid_batch_count:  11\n",
      "\tvalid_batch_count:  12\n",
      "\tvalid_batch_count:  13\n",
      "\tvalid_batch_count:  14\n",
      "\tvalid_batch_count:  15\n",
      "\tvalid_batch_count:  16\n",
      "\tvalid_batch_count:  17\n",
      "\tvalid_batch_count:  18\n",
      "\tvalid_batch_count:  19\n",
      "\tvalid_batch_count:  20\n",
      "\tvalid_batch_count:  21\n",
      "\tvalid_batch_count:  22\n",
      "\tvalid_batch_count:  23\n",
      "\tvalid_batch_count:  24\n",
      "\tvalid_batch_count:  25\n",
      "\tvalid_batch_count:  26\n",
      "\tvalid_batch_count:  27\n",
      "\tvalid_batch_count:  28\n",
      "\tvalid_batch_count:  29\n",
      "\tvalid_batch_count:  30\n",
      "\tvalid_batch_count:  31\n",
      "\tvalid_batch_count:  32\n",
      "\tvalid_batch_count:  33\n",
      "\tvalid_batch_count:  34\n",
      "\tvalid_batch_count:  35\n",
      "\tvalid_batch_count:  36\n",
      "\tvalid_batch_count:  37\n",
      "\tvalid_batch_count:  38\n",
      "\tvalid_batch_count:  39\n",
      "\tvalid_batch_count:  40\n",
      "\tvalid_batch_count:  41\n",
      "\tvalid_batch_count:  42\n",
      "\tvalid_batch_count:  43\n",
      "\tvalid_batch_count:  44\n",
      "\tvalid_batch_count:  45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalid_batch_count:  46\n",
      "\tvalid_batch_count:  47\n",
      "\tvalid_batch_count:  48\n",
      "\tvalid_batch_count:  49\n",
      "\tvalid_batch_count:  50\n",
      "\tvalid_batch_count:  51\n",
      "\tvalid_batch_count:  52\n",
      "\tvalid_batch_count:  53\n",
      "\tvalid_batch_count:  54\n",
      "\tvalid_batch_count:  55\n",
      "\tvalid_batch_count:  56\n",
      "\tvalid_batch_count:  57\n",
      "avg validation loss:  tensor(0.1869, device='cuda:0')\n",
      "Epoch [003] Minibatch = 10 Loss = 0.12 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 20 Loss = 0.11 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 30 Loss = 0.11 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 40 Loss = 0.13 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 50 Loss = 0.12 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 60 Loss = 0.12 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 70 Loss = 0.12 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 80 Loss = 0.12 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 90 Loss = 0.11 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 100 Loss = 0.13 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 110 Loss = 0.12 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 120 Loss = 0.13 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 130 Loss = 0.13 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 140 Loss = 0.13 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 150 Loss = 0.14 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 160 Loss = 0.13 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 170 Loss = 0.13 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 180 Loss = 0.14 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 190 Loss = 0.13 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 200 Loss = 0.13 lr = 0.01000 \n",
      "\tvalid_batch_count:  0\n",
      "\tvalid_batch_count:  1\n",
      "\tvalid_batch_count:  2\n",
      "\tvalid_batch_count:  3\n",
      "\tvalid_batch_count:  4\n",
      "\tvalid_batch_count:  5\n",
      "\tvalid_batch_count:  6\n",
      "\tvalid_batch_count:  7\n",
      "\tvalid_batch_count:  8\n",
      "\tvalid_batch_count:  9\n",
      "\tvalid_batch_count:  10\n",
      "\tvalid_batch_count:  11\n",
      "\tvalid_batch_count:  12\n",
      "\tvalid_batch_count:  13\n",
      "\tvalid_batch_count:  14\n",
      "\tvalid_batch_count:  15\n",
      "\tvalid_batch_count:  16\n",
      "\tvalid_batch_count:  17\n",
      "\tvalid_batch_count:  18\n",
      "\tvalid_batch_count:  19\n",
      "\tvalid_batch_count:  20\n",
      "\tvalid_batch_count:  21\n",
      "\tvalid_batch_count:  22\n",
      "\tvalid_batch_count:  23\n",
      "\tvalid_batch_count:  24\n",
      "\tvalid_batch_count:  25\n",
      "\tvalid_batch_count:  26\n",
      "\tvalid_batch_count:  27\n",
      "\tvalid_batch_count:  28\n",
      "\tvalid_batch_count:  29\n",
      "\tvalid_batch_count:  30\n",
      "\tvalid_batch_count:  31\n",
      "\tvalid_batch_count:  32\n",
      "\tvalid_batch_count:  33\n",
      "\tvalid_batch_count:  34\n",
      "\tvalid_batch_count:  35\n",
      "\tvalid_batch_count:  36\n",
      "\tvalid_batch_count:  37\n",
      "\tvalid_batch_count:  38\n",
      "\tvalid_batch_count:  39\n",
      "\tvalid_batch_count:  40\n",
      "\tvalid_batch_count:  41\n",
      "\tvalid_batch_count:  42\n",
      "\tvalid_batch_count:  43\n",
      "\tvalid_batch_count:  44\n",
      "\tvalid_batch_count:  45\n",
      "\tvalid_batch_count:  46\n",
      "\tvalid_batch_count:  47\n",
      "\tvalid_batch_count:  48\n",
      "\tvalid_batch_count:  49\n",
      "\tvalid_batch_count:  50\n",
      "\tvalid_batch_count:  51\n",
      "\tvalid_batch_count:  52\n",
      "\tvalid_batch_count:  53\n",
      "\tvalid_batch_count:  54\n",
      "\tvalid_batch_count:  55\n",
      "\tvalid_batch_count:  56\n",
      "\tvalid_batch_count:  57\n",
      "avg validation loss:  tensor(0.1806, device='cuda:0')\n",
      "Epoch [003] Minibatch = 210 Loss = 0.11 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 220 Loss = 0.13 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 230 Loss = 0.12 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 240 Loss = 0.13 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 250 Loss = 0.11 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 260 Loss = 0.12 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 270 Loss = 0.14 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 280 Loss = 0.12 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 290 Loss = 0.12 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 300 Loss = 0.13 lr = 0.01000 \n",
      "Epoch [003] Minibatch = 310 Loss = 0.12 lr = 0.01000 \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_loss, valid_loss = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot( X, Y, title, xlabel, ylabel, labels ):\n",
    "    for index, (x,y) in enumerate( zip( X, Y ) ):\n",
    "        plt.plot( x, y, label=labels[index] )\n",
    "    plt.legend(loc='best'); plt.title(title); plt.ylabel(ylabel); plt.xlabel(xlabel); plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_loss, valid_loss\n",
    "X, Y = [ range(0,10*len(train),10), range(0,205*len(val),205) ], [ train, val ]\n",
    "title, xlabel, ylabel = 'Loss vs Minibatches', 'Minibatches', 'Loss'\n",
    "labels = ['train', 'val' ]\n",
    "plot( X, Y, title, xlabel, ylabel, labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
