{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "import traceback\n",
    "import logging\n",
    "import importlib\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "%matplotlib inline\n",
    "\n",
    "from yolo_model import yoloModel\n",
    "from PASCAL_Dataloader import create_split_loaders\n",
    "from YOLO_Loss import YoloLoss\n",
    "\n",
    "total_loss = defaultdict(dict)\n",
    "avg_minibatch_loss = []\n",
    "avg_valid_loss = []\n",
    "avg_test_loss = defaultdict(dict)\n",
    "_validation_metrics = defaultdict(dict)\n",
    "tot_test_outputs = []\n",
    "tot_test_labels = []\n",
    "\n",
    "log = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    config['global_step'] = config.get('start_step', 0)\n",
    "    is_training = False if config.get('export_onnx') else True\n",
    "\n",
    "    # TODO: Load and initialize network\n",
    "    net = yoloModel(config)\n",
    "\n",
    "    # Define the optimizer and learning rate\n",
    "    optimizer = obtain_optimizer(config, net)\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer,\n",
    "        step_size=config['decay_step'],\n",
    "        gamma=config['decay_gamma'])\n",
    "\n",
    "    # Use pretrained model\n",
    "    if config['pretrain_snapshot']:\n",
    "        logging.info('Load pretrained weights from {}'.format(config['pretrain_snapshot']))\n",
    "        state_dict = torch.load(config['pretrain_snapshot'])\n",
    "        net.load_state_dict(state_dict)\n",
    "\n",
    "    # Use all 3 scales for computing YOLO loss\n",
    "    YOLO_losses = []\n",
    "    val_YOLO_losses = []\n",
    "    test_YOLO_losses = []\n",
    "    for i in range(3):\n",
    "        YOLO_losses.append(YoloLoss(config['classes'], (config['img_w'], config['img_h']), config['anchors'][i]))\n",
    "        val_YOLO_losses.append(YoloLoss(config['classes'], (config['img_w'], config['img_h']), config['anchors'][i]))\n",
    "        test_YOLO_losses.append(YoloLoss(config['classes'], (config['img_w'], config['img_h']), config['anchors'][i]))\n",
    "\n",
    "    # Check if your system supports CUDA\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "\n",
    "    # Setup GPU optimization if CUDA is supported\n",
    "    if use_cuda:\n",
    "        computing_device = torch.device(\"cuda\")\n",
    "        extras = {\"num_workers\": 3, \"pin_memory\": True}\n",
    "        print(\"CUDA is supported\")\n",
    "    else: # Otherwise, train on the CPU\n",
    "        computing_device = torch.device(\"cpu\")\n",
    "        extras = False\n",
    "        print(\"CUDA NOT supported\")\n",
    "    \n",
    "    # Load in data \n",
    "    root_dir = os.getcwd()\n",
    "    train_loader, val_loader, test_loader = create_split_loaders(config['batch_size'])\n",
    "    \n",
    "    # Instantiate model to run on the GPU or CPU based on CUDA support\n",
    "    net = net.to(computing_device)\n",
    "    print(\"Model on CUDA?\", next(net.parameters()).is_cuda)\n",
    "    \n",
    "    # Begin training loop\n",
    "    print(\"Start training:\")\n",
    "    for epoch in range(config['epochs']):\n",
    "        N_minibatch_loss = 0.0\n",
    "        for minibatch, samples in enumerate(train_loader):\n",
    "            images, labels = samples[\"image\"], samples[\"label\"]\n",
    "            #print(labels)\n",
    "            start_time = time.time()\n",
    "            config['global_step'] += 1\n",
    "                \n",
    "            #images = images.unsqueeze(0)\n",
    "\n",
    "            # Put the minibatch data in CUDA Tensors and run on the GPU if supported\n",
    "            images = images.to(computing_device)\n",
    "            #labels = labels.to(computing_device)\n",
    "\n",
    "            # Forward and backward\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            #print(outputs.shape)\n",
    "            loss_names = [\"total_loss\", \"x\", \"y\", \"w\", \"h\", \"conf\", \"cls\"]\n",
    "            losses = []\n",
    "            for z in range(len(loss_names)):\n",
    "                losses.append([])\n",
    "            for i in range(3):\n",
    "                loss_item = YOLO_losses[i](outputs[i], labels)\n",
    "                for j, l in enumerate(loss_item):\n",
    "                    losses[j].append(l)\n",
    "            losses = [sum(l) for l in losses]\n",
    "            loss = losses[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Add this iteration's loss to the total_loss\n",
    "            total_loss[epoch][minibatch] = loss.item()\n",
    "            N_minibatch_loss += loss\n",
    "\n",
    "            if minibatch > 0 and minibatch % 10 == 0:\n",
    "                _loss = loss.item()\n",
    "                N_minibatch_loss /= 10\n",
    "                lr = optimizer.param_groups[0]['lr']\n",
    "                logging.info('Epoch [%.3d] Minibatch = %d Loss = %.2f lr = %.5f '%\n",
    "                    (epoch, minibatch, N_minibatch_loss, lr))\n",
    "                print('Epoch [%.3d] Minibatch = %d Loss = %.2f lr = %.5f '%\n",
    "                    (epoch, minibatch, N_minibatch_loss, lr))\n",
    "                \n",
    "                # Add the averaged loss over N minibatches and reset the counter\n",
    "                avg_minibatch_loss.append(N_minibatch_loss.item())\n",
    "                N_minibatch_loss = 0.0\n",
    "            \n",
    "                for i, name in enumerate(loss_names):\n",
    "                    value = _loss if i == 0 else losses[i]\n",
    "\n",
    "            if epoch==0 and minibatch % 205 == 0:\n",
    "                save_checkpoint(net.state_dict(), config)\n",
    "                \n",
    "                # Implement cross-validation\n",
    "                val_loss = 0\n",
    "                sum_val_loss = 0\n",
    "                validation_outputs = []\n",
    "                validation_labels = []\n",
    "                with torch.no_grad():\n",
    "                    for valid_batch_count, samples in enumerate(val_loader):\n",
    "                        val_images, val_labels = samples[\"image\"], samples[\"label\"]\n",
    "                        val_images = val_images.to(computing_device)\n",
    "                        val_outputs = net(val_images)\n",
    "                        val_losses = []\n",
    "                        for z in range(len(loss_names)):\n",
    "                            val_losses.append([])\n",
    "                        for i in range(3):\n",
    "                            val_loss_item = val_YOLO_losses[i](val_outputs[i], val_labels)\n",
    "                            for j, l in enumerate(val_loss_item):\n",
    "                                val_losses[j].append(l)\n",
    "                        val_losses = [sum(l) for l in val_losses]\n",
    "                        val_loss = val_losses[0]\n",
    "                        sum_val_loss += val_loss\n",
    "                        print(\"\\tvalid_batch_count: \", valid_batch_count)\n",
    "\n",
    "                    sum_val_loss /= len(val_loader)\n",
    "                    print(\"avg validation loss: \", sum_val_loss)\n",
    "                    avg_valid_loss.append(sum_val_loss.item())\n",
    "                    \n",
    "\n",
    "            if epoch > 0 and minibatch > 0 and minibatch % 205 == 0:\n",
    "                save_checkpoint(net.state_dict(), config)\n",
    "                \n",
    "                # Implement cross-validation\n",
    "                val_loss = 0\n",
    "                sum_val_loss = 0\n",
    "                validation_outputs = []\n",
    "                validation_labels = []\n",
    "                with torch.no_grad():\n",
    "                    for valid_batch_count, samples in enumerate(val_loader):\n",
    "                        val_images, val_labels = samples[\"image\"], samples[\"label\"]\n",
    "                        val_images = val_images.to(computing_device)\n",
    "                        val_outputs = net(val_images)\n",
    "                        val_losses = []\n",
    "                        for z in range(len(loss_names)):\n",
    "                            val_losses.append([])\n",
    "                        for i in range(3):\n",
    "                            val_loss_item = val_YOLO_losses[i](val_outputs[i], val_labels)\n",
    "                            for j, l in enumerate(val_loss_item):\n",
    "                                val_losses[j].append(l)\n",
    "                        val_losses = [sum(l) for l in val_losses]\n",
    "                        val_loss = val_losses[0]\n",
    "                        sum_val_loss += val_loss\n",
    "                        print(\"\\tvalid_batch_count: \", valid_batch_count)\n",
    "\n",
    "                    sum_val_loss /= len(val_loader)\n",
    "                    print(\"avg validation loss: \", sum_val_loss)\n",
    "                    avg_valid_loss.append(sum_val_loss.item())\n",
    "                    \n",
    "        lr_scheduler.step()\n",
    "\n",
    "    save_checkpoint(net.state_dict(), config)\n",
    "    print('Training Complete')\n",
    "    \n",
    "    test_loss = 0\n",
    "    sum_test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for test_batch_count, samples in enumerate(test_loader):\n",
    "            test_images, test_labels = samples[\"image\"], samples[\"label\"]\n",
    "            print(\"\\ttest_batch_count: \", test_batch_count)\n",
    "            test_images= test_images.to(computing_device)\n",
    "            test_outputs = net(test_images)\n",
    "            test_losses = []\n",
    "            for z in range(len(loss_names)):\n",
    "                test_losses.append([])\n",
    "            for i in range(3):\n",
    "                test_loss_item = test_YOLO_losses[i](test_outputs[i], test_labels)\n",
    "                for j, l in enumerate(val_loss_item):\n",
    "                    test_losses[j].append(l)\n",
    "            test_losses = [sum(l) for l in test_losses]\n",
    "            test_loss = test_losses[0]\n",
    "            sum_test_loss += test_loss\n",
    "\n",
    "        sum_test_loss /= len(test_loader)\n",
    "        print(\"avg test loss: \", sum_test_loss)\n",
    "        avg_test_loss[epoch] = test_loss.item()\n",
    "    \n",
    "    return avg_minibatch_loss, avg_valid_loss\n",
    "\n",
    "    \n",
    "def save_checkpoint(state_dict, config, evaluate_func=None):\n",
    "        \n",
    "    checkpoint_path = os.path.join(config[\"sub_working_dir\"], \"model.pth\")\n",
    "    torch.save(state_dict, checkpoint_path)\n",
    "    logging.info(\"Model checkpoint saved to %s\" % checkpoint_path)\n",
    "\n",
    "\n",
    "def obtain_optimizer(config, net):\n",
    "    optimizer = None\n",
    "\n",
    "    # Assign different learning rate for each layer\n",
    "    params = None\n",
    "    base_parameters = list(\n",
    "        map(id, net.backbone.parameters())\n",
    "    )\n",
    "    logits_parameters = filter(lambda p: id(p) not in base_parameters, net.parameters())\n",
    "\n",
    "    if not config['freeze_backbone']:\n",
    "        parameters = [\n",
    "            {\"params\": logits_parameters, \"lr\": config['other_lr']},\n",
    "            {\"params\": net.backbone.parameters(), \"lr\": config['backbone_lr']},\n",
    "        ]\n",
    "    else:\n",
    "        print(\"Freezing backbone parameters\")\n",
    "        for p in net.backbone.parameters():\n",
    "            p.requires_grad = False\n",
    "        parameters = [\n",
    "            {\"params\": logits_parameters, \"lr\": config['other_lr']},\n",
    "        ]\n",
    "\n",
    "    # Initialize optimizer class\n",
    "    if config['optimizer_type'] == \"adam\":\n",
    "        optimizer = optim.Adam(params, weight_decay=config['optimizer_weight_decay'])\n",
    "    elif config['optimizer_type'] == \"amsgrad\":\n",
    "        optimizer = optim.Adam(params, weight_decay=config['optimizer_weight_decay'], amsgrad=True)\n",
    "    elif config['optimizer_type'] == \"rmsprop\":\n",
    "        optimizer = optim.RMSprop(params, weight_decay=config['optimizer_weight_decay'])\n",
    "    else:\n",
    "        optimizer = optim.SGD(parameters, momentum=0.9, weight_decay=config['optimizer_weight_decay'],\n",
    "                              nesterov=(config['optimizer_type'] == \"nesterov\"))\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(arch=None, init=None, optim=None, output_file=None):\n",
    "    \n",
    "    if output_file is None:\n",
    "        output_file = \"_\".join([str(datetime.now().strftime(\"%Y%m%d-%H%M%S\"))]) + \".json\"\n",
    "        print(output_file)\n",
    "        \n",
    "    log['data'] = {\n",
    "        'total_loss': total_loss,\n",
    "        'avg_minibatch_loss': avg_minibatch_loss,\n",
    "        'avg_valid_loss': avg_valid_loss,\n",
    "        'validation_metrics': _validation_metrics,\n",
    "        'test_outputs': tot_test_outputs,\n",
    "        'test_labels': tot_test_labels\n",
    "    }\n",
    "        \n",
    "    with open(\"logs/\" + output_file, 'w') as f:\n",
    "        json.dump(log, f, indent=4)\n",
    "    \n",
    "    # Initialize hyperparameters/variables\n",
    "    config = {}\n",
    "    config['backbone_name'] = \"darknet_53\"\n",
    "    config['backbone_pretrained'] = \"./darknet53_weights_pytorch.pth\" # set empty to disable\n",
    "    \n",
    "    config['anchors'] = [[[116, 90], [156, 198], [373, 326]],\n",
    "                                [[30, 61], [62, 45], [59, 119]],\n",
    "                                [[10, 13], [16, 30], [33, 23]]]\n",
    "    config['classes'] = 20\n",
    "    \n",
    "    config['backbone_lr'] = 0.001\n",
    "    config['other_lr'] = 0.01\n",
    "    config['freeze_backbone'] = False   #  freeze backbone wegiths to finetune\n",
    "    config['decay_gamma'] = 0.5\n",
    "    config['decay_step'] = 6         #  decay lr in every ? epochs\n",
    "    \n",
    "    config['optimizer_type'] = \"sgd\"\n",
    "    config['optimizer_weight_decay'] = 4e-05\n",
    "    \n",
    "    config['batch_size'] = 20  # Number of training samples per batch to be passed to network\n",
    "    config['epochs'] = 10  # Number of epochs to train the model\n",
    "    config['img_h'] = config['img_w'] = 416\n",
    "    config['seed'] = np.random.seed()\n",
    "    config['working_dir'] = \"./states\"     #  replace with your working dir\n",
    "    \n",
    "    def get_latest_states(dirpath):\n",
    "        \"\"\"\n",
    "        Get the latest image file in the given directory\n",
    "        \"\"\"\n",
    "        # get filepaths of all files and dirs in the given dir\n",
    "        valid_files = [os.path.join(dirpath, filename) for filename in os.listdir(dirpath)]\n",
    "\n",
    "        return max(valid_files, key=os.path.getmtime)\n",
    "   \n",
    "    \n",
    "    # Create sub_working_dir\n",
    "    sub_working_dir = '{}/{}'.format(\n",
    "        config['working_dir'], time.strftime(\"%Y%m%d%H%M%S\", time.localtime()))\n",
    "    if not os.path.exists(sub_working_dir):\n",
    "        os.makedirs(sub_working_dir)\n",
    "    config[\"sub_working_dir\"] = sub_working_dir\n",
    "    logging.info(\"sub working dir: %s\" % sub_working_dir)\n",
    "    \n",
    "    if not os.path.exists(os.path.join(sub_working_dir, \"model.pth\")):\n",
    "        config['pretrain_snapshot'] = \"\"\n",
    "    else:\n",
    "        config['pretrain_snapshot'] = os.path.join(get_latest_states(config['working_dir']), \"model.pth\")  # load checkpoint\n",
    "\n",
    "    # Start training\n",
    "    train_loss, valid_loss = train(config)\n",
    "    \n",
    "    return train_loss, valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20190603-192132.json\n",
      "CUDA is supported\n",
      "Model on CUDA? True\n",
      "Start training:\n",
      "\tvalid_batch_count:  0\n",
      "\tvalid_batch_count:  1\n",
      "\tvalid_batch_count:  2\n",
      "\tvalid_batch_count:  3\n",
      "\tvalid_batch_count:  4\n",
      "\tvalid_batch_count:  5\n",
      "\tvalid_batch_count:  6\n",
      "\tvalid_batch_count:  7\n",
      "\tvalid_batch_count:  8\n",
      "\tvalid_batch_count:  9\n",
      "\tvalid_batch_count:  10\n",
      "\tvalid_batch_count:  11\n",
      "\tvalid_batch_count:  12\n",
      "\tvalid_batch_count:  13\n",
      "\tvalid_batch_count:  14\n",
      "\tvalid_batch_count:  15\n",
      "\tvalid_batch_count:  16\n",
      "\tvalid_batch_count:  17\n",
      "\tvalid_batch_count:  18\n",
      "\tvalid_batch_count:  19\n",
      "\tvalid_batch_count:  20\n",
      "\tvalid_batch_count:  21\n",
      "\tvalid_batch_count:  22\n",
      "\tvalid_batch_count:  23\n",
      "\tvalid_batch_count:  24\n",
      "\tvalid_batch_count:  25\n",
      "\tvalid_batch_count:  26\n",
      "\tvalid_batch_count:  27\n",
      "\tvalid_batch_count:  28\n",
      "\tvalid_batch_count:  29\n",
      "\tvalid_batch_count:  30\n",
      "\tvalid_batch_count:  31\n",
      "\tvalid_batch_count:  32\n",
      "\tvalid_batch_count:  33\n",
      "\tvalid_batch_count:  34\n",
      "\tvalid_batch_count:  35\n",
      "\tvalid_batch_count:  36\n",
      "\tvalid_batch_count:  37\n",
      "\tvalid_batch_count:  38\n",
      "\tvalid_batch_count:  39\n",
      "\tvalid_batch_count:  40\n",
      "\tvalid_batch_count:  41\n",
      "\tvalid_batch_count:  42\n",
      "\tvalid_batch_count:  43\n",
      "\tvalid_batch_count:  44\n",
      "\tvalid_batch_count:  45\n",
      "\tvalid_batch_count:  46\n",
      "\tvalid_batch_count:  47\n",
      "\tvalid_batch_count:  48\n",
      "\tvalid_batch_count:  49\n",
      "\tvalid_batch_count:  50\n",
      "\tvalid_batch_count:  51\n",
      "\tvalid_batch_count:  52\n",
      "\tvalid_batch_count:  53\n",
      "\tvalid_batch_count:  54\n",
      "\tvalid_batch_count:  55\n",
      "\tvalid_batch_count:  56\n",
      "\tvalid_batch_count:  57\n",
      "avg validation loss:  tensor(3.1431, device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c4e4f3d34f78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-ca131cc61584>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(arch, init, optim, output_file)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-2d293b325c83>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0mloss_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                     \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/home-01/41/741/tjwest/Multi-Object-Detection/YOLO_Loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m     52\u001b[0m             mask, noobj_mask, t_x, t_y, t_w, t_h, t_conf, t_class = self.parse_targets(targets, anchors_scaled,\n\u001b[1;32m     53\u001b[0m                                                                                \u001b[0mgrid_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_h\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                                                                                self.threshold)\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0;31m# Move variables to CUDA device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoobj_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_conf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoobj_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/home-01/41/741/tjwest/Multi-Object-Detection/YOLO_Loss.py\u001b[0m in \u001b[0;36mparse_targets\u001b[0;34m(self, targets, anchors, grid_w, grid_h, threshold)\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;31m#Convert positions to make them relative to box\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrid_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mg_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrid_h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                 \u001b[0mg_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrid_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mg_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrid_h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_loss, valid_loss = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot( X, Y, title, xlabel, ylabel, labels ):\n",
    "    for index, (x,y) in enumerate( zip( X, Y ) ):\n",
    "        plt.plot( x, y, label=labels[index] )\n",
    "    plt.legend(loc='best'); plt.title(title); plt.ylabel(ylabel); plt.xlabel(xlabel); plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_loss, valid_loss\n",
    "X, Y = [ range(0,10*len(train),10), range(0,205*len(val),205) ], [ train, val ]\n",
    "title, xlabel, ylabel = 'Loss vs Minibatches', 'Minibatches', 'Loss'\n",
    "labels = ['train', 'val' ]\n",
    "plot( X, Y, title, xlabel, ylabel, labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
