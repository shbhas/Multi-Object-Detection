{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import importlib\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from yolo_model import yoloModel\n",
    "from PASCAL_Dataloader import create_split_loaders\n",
    "from YOLO_Loss import YoloLoss\n",
    "from utils import NMS\n",
    "from boundbox import IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(config):\n",
    "    \n",
    "    # Check if your system supports CUDA\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    \n",
    "    # Setup GPU optimization if CUDA is supported\n",
    "    if use_cuda:\n",
    "        computing_device = torch.device(\"cuda\")\n",
    "        extras = {\"num_workers\": 3, \"pin_memory\": True}\n",
    "        print(\"CUDA is supported\")\n",
    "    else: # Otherwise, train on the CPU\n",
    "        computing_device = torch.device(\"cpu\")\n",
    "        extras = False\n",
    "        print(\"CUDA NOT supported\")\n",
    "        \n",
    "    # Load and initialize network\n",
    "    net = yoloModel(config)\n",
    "    net = net.to(computing_device)\n",
    "\n",
    "    # Restore pretrain model\n",
    "    if config[\"pretrain_snapshot\"]:\n",
    "        state_dict = torch.load(config[\"pretrain_snapshot\"])\n",
    "        net.load_state_dict(state_dict)\n",
    "    else:\n",
    "        print(\"Error: missing pretrain_snapshot\")\n",
    "\n",
    "    # Calculate YOLO loss at 3 different scales\n",
    "    YOLO_losses = []\n",
    "    for i in range(3):\n",
    "        YOLO_losses.append(YoloLoss(config[\"classes\"], (config[\"img_w\"], config[\"img_h\"]), config[\"anchors\"][i]))\n",
    "\n",
    "    # Test DataLoader\n",
    "    root_dir = os.getcwd()\n",
    "    train_loader, val_loader, test_loader = create_split_loaders(root_dir, config['batch_size'])\n",
    "\n",
    "    # Start the eval loop\n",
    "    print(\"Start eval.\")\n",
    "    count = 0\n",
    "    correct = 0\n",
    "    for n, samples in enumerate(test_loader):\n",
    "        images, labels = samples[\"image\"], samples[\"label\"]\n",
    "        images, labels = images.to(computing_device), labels.to(computing_device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = net(images)\n",
    "            list_of_outputs = []\n",
    "            for i in range(3):\n",
    "                list_of_outputs.append(YOLO_losses[i](outputs[i]))\n",
    "            final_output = torch.cat(list_of_outputs, 1)\n",
    "            final_output = NMS(final_output, config[\"classes\"], conf_thresh=0.2)\n",
    "            \n",
    "            #  Calculate mAP\n",
    "            for i in range(labels.size(0)):\n",
    "                \n",
    "                # Get the labels for samples where the width is not zero\n",
    "                t_samp = labels[i, labels[i, :, 3] != 0]\n",
    "                for obj_class, t_x, t_y, t_w, t_h in t_samp:\n",
    "                    count += 1\n",
    "                    \n",
    "                    # Obtain rescaled ground truth coordinates\n",
    "                    t_xmin, t_xmax = config[\"img_w\"] * (t_x - t_w / 2), config[\"img_w\"] * (t_x + t_w / 2)\n",
    "                    t_ymin, t_ymax = config[\"img_h\"] * (t_y - t_h / 2), config[\"img_h\"] * (t_y + t_h / 2)\n",
    "                    \n",
    "                    ground_truth_box = torch.cat([coord.unsqueeze(0) for coord in [t_xmin, t_ymin, t_xmax, t_ymax]]).view(1, -1)\n",
    "                    ground_truth_box = ground_truth_box.float()\n",
    "                    samp_pred = final_output[i]\n",
    "                    if samp_pred is not None:\n",
    "                        \n",
    "                        # Find IOU of predictions where the class predicted is same as ground truth\n",
    "                        for xmin, ymin, xmax, ymax, conf, obj_conf, obj_pred in samp_pred[samp_pred[:, 6] == obj_class.float()]:\n",
    "                            box_pred = torch.cat([coord.unsqueeze(0) for coord in [xmin, ymin, xmax, ymax]]).view(1, -1)\n",
    "                            #print('Pred:',box_pred)\n",
    "                            #print('GT:',box_gt)\n",
    "                            iou = IOU(box_pred, ground_truth_box)\n",
    "                            if iou >= config[\"confidence_threshold\"]:\n",
    "                                correct += 1\n",
    "                                break\n",
    "        if count:\n",
    "            print('Batch [%d/%d] mAP: %.5f' % (n, len(test_loader), float(correct / count)))\n",
    "\n",
    "    print('Mean Average Precision: %.5f' % float(correct / count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n",
      "Start eval.\n",
      "Batch [0/130] mAP: 0.83721\n",
      "Batch [1/130] mAP: 0.88506\n",
      "Batch [2/130] mAP: 0.87402\n",
      "Batch [3/130] mAP: 0.84324\n",
      "Batch [4/130] mAP: 0.83710\n",
      "Batch [5/130] mAP: 0.83088\n",
      "Batch [6/130] mAP: 0.83489\n",
      "Batch [7/130] mAP: 0.84960\n",
      "Batch [8/130] mAP: 0.85096\n",
      "Batch [9/130] mAP: 0.85376\n",
      "Batch [10/130] mAP: 0.86117\n",
      "Batch [11/130] mAP: 0.86085\n",
      "Batch [12/130] mAP: 0.86882\n",
      "Batch [13/130] mAP: 0.87159\n",
      "Batch [14/130] mAP: 0.87373\n",
      "Batch [15/130] mAP: 0.87448\n",
      "Batch [16/130] mAP: 0.86632\n",
      "Batch [17/130] mAP: 0.86567\n",
      "Batch [18/130] mAP: 0.86972\n",
      "Batch [19/130] mAP: 0.86538\n",
      "Batch [20/130] mAP: 0.85776\n",
      "Batch [21/130] mAP: 0.86307\n",
      "Batch [22/130] mAP: 0.85868\n",
      "Batch [23/130] mAP: 0.85393\n",
      "Batch [24/130] mAP: 0.85522\n",
      "Batch [25/130] mAP: 0.85592\n",
      "Batch [26/130] mAP: 0.85526\n",
      "Batch [27/130] mAP: 0.86019\n",
      "Batch [28/130] mAP: 0.85911\n",
      "Batch [29/130] mAP: 0.86055\n",
      "Batch [30/130] mAP: 0.85994\n",
      "Batch [31/130] mAP: 0.86158\n",
      "Batch [32/130] mAP: 0.86395\n",
      "Batch [33/130] mAP: 0.86456\n",
      "Batch [34/130] mAP: 0.86562\n",
      "Batch [35/130] mAP: 0.86198\n",
      "Batch [36/130] mAP: 0.86230\n",
      "Batch [37/130] mAP: 0.86375\n",
      "Batch [38/130] mAP: 0.86486\n",
      "Batch [39/130] mAP: 0.86304\n",
      "Batch [40/130] mAP: 0.86483\n",
      "Batch [41/130] mAP: 0.86641\n",
      "Batch [42/130] mAP: 0.86491\n",
      "Batch [43/130] mAP: 0.86361\n",
      "Batch [44/130] mAP: 0.86464\n",
      "Batch [45/130] mAP: 0.86460\n",
      "Batch [46/130] mAP: 0.86441\n",
      "Batch [47/130] mAP: 0.86455\n",
      "Batch [48/130] mAP: 0.86153\n",
      "Batch [49/130] mAP: 0.86138\n",
      "Batch [50/130] mAP: 0.86059\n",
      "Batch [51/130] mAP: 0.86014\n",
      "Batch [52/130] mAP: 0.86139\n",
      "Batch [53/130] mAP: 0.86257\n",
      "Batch [54/130] mAP: 0.86270\n",
      "Batch [55/130] mAP: 0.86322\n",
      "Batch [56/130] mAP: 0.86177\n",
      "Batch [57/130] mAP: 0.86310\n",
      "Batch [58/130] mAP: 0.86346\n",
      "Batch [59/130] mAP: 0.86324\n",
      "Batch [60/130] mAP: 0.86259\n",
      "Batch [61/130] mAP: 0.86301\n",
      "Batch [62/130] mAP: 0.86219\n",
      "Batch [63/130] mAP: 0.86357\n",
      "Batch [64/130] mAP: 0.86340\n",
      "Batch [65/130] mAP: 0.86485\n",
      "Batch [66/130] mAP: 0.86509\n",
      "Batch [67/130] mAP: 0.86558\n",
      "Batch [68/130] mAP: 0.86561\n",
      "Batch [69/130] mAP: 0.86527\n",
      "Batch [70/130] mAP: 0.86417\n",
      "Batch [71/130] mAP: 0.86410\n",
      "Batch [72/130] mAP: 0.86450\n",
      "Batch [73/130] mAP: 0.86519\n",
      "Batch [74/130] mAP: 0.86638\n",
      "Batch [75/130] mAP: 0.86665\n",
      "Batch [76/130] mAP: 0.86625\n",
      "Batch [77/130] mAP: 0.86675\n",
      "Batch [78/130] mAP: 0.86645\n",
      "Batch [79/130] mAP: 0.86709\n",
      "Batch [80/130] mAP: 0.86778\n",
      "Batch [81/130] mAP: 0.86826\n",
      "Batch [82/130] mAP: 0.86897\n",
      "Batch [83/130] mAP: 0.86844\n",
      "Batch [84/130] mAP: 0.86942\n",
      "Batch [85/130] mAP: 0.86939\n",
      "Batch [86/130] mAP: 0.86933\n",
      "Batch [87/130] mAP: 0.86809\n",
      "Batch [88/130] mAP: 0.86764\n",
      "Batch [89/130] mAP: 0.86738\n",
      "Batch [90/130] mAP: 0.86745\n",
      "Batch [91/130] mAP: 0.86557\n",
      "Batch [92/130] mAP: 0.86628\n",
      "Batch [93/130] mAP: 0.86454\n",
      "Batch [94/130] mAP: 0.86482\n",
      "Batch [95/130] mAP: 0.86527\n",
      "Batch [96/130] mAP: 0.86343\n",
      "Batch [97/130] mAP: 0.86360\n",
      "Batch [98/130] mAP: 0.86278\n",
      "Batch [99/130] mAP: 0.86182\n",
      "Batch [100/130] mAP: 0.86261\n",
      "Batch [101/130] mAP: 0.86226\n",
      "Batch [102/130] mAP: 0.86193\n",
      "Batch [103/130] mAP: 0.86118\n",
      "Batch [104/130] mAP: 0.86133\n",
      "Batch [105/130] mAP: 0.86178\n",
      "Batch [106/130] mAP: 0.86239\n",
      "Batch [107/130] mAP: 0.86263\n",
      "Batch [108/130] mAP: 0.86272\n",
      "Batch [109/130] mAP: 0.86310\n",
      "Batch [110/130] mAP: 0.86320\n",
      "Batch [111/130] mAP: 0.86372\n",
      "Batch [112/130] mAP: 0.86392\n",
      "Batch [113/130] mAP: 0.86384\n",
      "Batch [114/130] mAP: 0.86431\n",
      "Batch [115/130] mAP: 0.86497\n",
      "Batch [116/130] mAP: 0.86480\n",
      "Batch [117/130] mAP: 0.86546\n",
      "Batch [118/130] mAP: 0.86599\n",
      "Batch [119/130] mAP: 0.86554\n",
      "Batch [120/130] mAP: 0.86408\n",
      "Batch [121/130] mAP: 0.86485\n",
      "Batch [122/130] mAP: 0.86493\n",
      "Batch [123/130] mAP: 0.86510\n",
      "Batch [124/130] mAP: 0.86525\n",
      "Batch [125/130] mAP: 0.86487\n",
      "Batch [126/130] mAP: 0.86467\n",
      "Batch [127/130] mAP: 0.86531\n",
      "Batch [128/130] mAP: 0.86570\n",
      "Batch [129/130] mAP: 0.86590\n",
      "Mean Average Precision: 0.86590\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    config = {}\n",
    "    config[\"batch_size\"] = 16\n",
    "    config['backbone_name'] = \"darknet_53\"\n",
    "    config['backbone_pretrained'] = \"\"\n",
    "    config['anchors'] = [[[116, 90], [156, 198], [373, 326]],\n",
    "                                [[30, 61], [62, 45], [59, 119]],\n",
    "                                [[10, 13], [16, 30], [33, 23]]]\n",
    "    config['classes'] = 20\n",
    "    config['img_h'] = config['img_w'] = 416\n",
    "    config['confidence_threshold'] = 0.5\n",
    "    config['pretrain_snapshot'] = \"./states/20190531143702/model.pth\"\n",
    "    config['classes_names_path'] = \"./data/voc.names\"\n",
    "\n",
    "    # Start training\n",
    "    evaluate(config)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
