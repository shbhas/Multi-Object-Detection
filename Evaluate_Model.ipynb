{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import importlib\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from yolo_model import yoloModel\n",
    "from PASCAL_Dataloader import create_split_loaders\n",
    "from YOLO_Loss import YoloLoss\n",
    "from utils import NMS\n",
    "from bbox import bbox_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(config):\n",
    "    \n",
    "    # Check if your system supports CUDA\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    \n",
    "    # Setup GPU optimization if CUDA is supported\n",
    "    if use_cuda:\n",
    "        computing_device = torch.device(\"cuda\")\n",
    "        extras = {\"num_workers\": 3, \"pin_memory\": True}\n",
    "        print(\"CUDA is supported\")\n",
    "    else: # Otherwise, train on the CPU\n",
    "        computing_device = torch.device(\"cpu\")\n",
    "        extras = False\n",
    "        print(\"CUDA NOT supported\")\n",
    "        \n",
    "    # Load and initialize network\n",
    "    net = yoloModel(config)\n",
    "    net = net.to(computing_device)\n",
    "\n",
    "    # Restore pretrain model\n",
    "    if config[\"pretrain_snapshot\"]:\n",
    "        state_dict = torch.load(config[\"pretrain_snapshot\"])\n",
    "        net.load_state_dict(state_dict)\n",
    "    else:\n",
    "        print(\"Error: missing pretrain_snapshot\")\n",
    "\n",
    "    # Calculate YOLO loss at 3 different scales\n",
    "    YOLO_losses = []\n",
    "    for i in range(3):\n",
    "        YOLO_losses.append(YoloLoss(config[\"classes\"], (config[\"img_w\"], config[\"img_h\"]), config[\"anchors\"][i]))\n",
    "\n",
    "    # Test DataLoader\n",
    "    root_dir = os.getcwd()\n",
    "    train_loader, val_loader, test_loader = create_split_loaders(root_dir, config['batch_size'])\n",
    "\n",
    "    # Start the eval loop\n",
    "    print(\"Start eval.\")\n",
    "    count = 0\n",
    "    correct = 0\n",
    "    for n, samples in enumerate(test_loader):\n",
    "        images, labels = samples[\"image\"], samples[\"label\"]\n",
    "        images, labels = images.to(computing_device), labels.to(computing_device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = net(images)\n",
    "            list_of_outputs = []\n",
    "            for i in range(3):\n",
    "                list_of_outputs.append(YOLO_losses[i](outputs[i]))\n",
    "            final_output = torch.cat(list_of_outputs, 1)\n",
    "            final_output = NMS(final_output, config[\"classes\"], conf_thresh=0.2)\n",
    "            \n",
    "            #  Calculate mAP\n",
    "            for i in range(labels.size(0)):\n",
    "                \n",
    "                # Get the labels for samples where the width is not zero\n",
    "                t_samp = labels[i, labels[i, :, 3] != 0]\n",
    "                for obj_class, t_x, t_y, t_w, t_h in t_samp:\n",
    "                    count += 1\n",
    "                    \n",
    "                    # Obtain rescaled ground truth coordinates\n",
    "                    t_xmin, t_xmax = config[\"img_w\"] * (t_x - t_w / 2), config[\"img_w\"] * (t_x + t_w / 2)\n",
    "                    t_ymin, t_ymax = config[\"img_h\"] * (t_y - t_h / 2), config[\"img_h\"] * (t_y + t_h / 2)\n",
    "                    \n",
    "                    ground_truth_box = torch.cat([coord.unsqueeze(0) for coord in [t_xmin, t_ymin, t_xmax, t_ymax]]).view(1, -1)\n",
    "                    ground_truth_box = ground_truth_box.float()\n",
    "                    samp_pred = final_output[i]\n",
    "                    if samp_pred is not None:\n",
    "                        \n",
    "                        # Find IOU of predictions where the class predicted is same as ground truth\n",
    "                        for xmin, ymin, xmax, ymax, conf, obj_conf, obj_pred in samp_pred[samp_pred[:, 6] == obj_class.float()]:\n",
    "                            box_pred = torch.cat([coord.unsqueeze(0) for coord in [xmin, ymin, xmax, ymax]]).view(1, -1)\n",
    "                            #print('Pred:',box_pred)\n",
    "                            #print('GT:',box_gt)\n",
    "                            iou = bbox_iou(box_pred, ground_truth_box)\n",
    "                            if iou >= config[\"confidence_threshold\"]:\n",
    "                                correct += 1\n",
    "                                break\n",
    "        if count:\n",
    "            print('Batch [%d/%d] mAP: %.5f' % (n, len(test_loader), float(correct / count)))\n",
    "\n",
    "    print('Mean Average Precision: %.5f' % float(correct / count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n",
      "Start eval.\n",
      "Batch [0/130] mAP: 0.38298\n",
      "Batch [1/130] mAP: 0.44565\n",
      "Batch [2/130] mAP: 0.45161\n",
      "Batch [3/130] mAP: 0.42604\n",
      "Batch [4/130] mAP: 0.40807\n",
      "Batch [5/130] mAP: 0.40892\n",
      "Batch [6/130] mAP: 0.39871\n",
      "Batch [7/130] mAP: 0.39669\n",
      "Batch [8/130] mAP: 0.39059\n",
      "Batch [9/130] mAP: 0.39785\n",
      "Batch [10/130] mAP: 0.40351\n",
      "Batch [11/130] mAP: 0.39267\n",
      "Batch [12/130] mAP: 0.39835\n",
      "Batch [13/130] mAP: 0.40310\n",
      "Batch [14/130] mAP: 0.40343\n",
      "Batch [15/130] mAP: 0.41281\n",
      "Batch [16/130] mAP: 0.42248\n",
      "Batch [17/130] mAP: 0.41920\n",
      "Batch [18/130] mAP: 0.41860\n",
      "Batch [19/130] mAP: 0.42316\n",
      "Batch [20/130] mAP: 0.43133\n",
      "Batch [21/130] mAP: 0.42683\n",
      "Batch [22/130] mAP: 0.42815\n",
      "Batch [23/130] mAP: 0.42709\n",
      "Batch [24/130] mAP: 0.42949\n",
      "Batch [25/130] mAP: 0.42731\n",
      "Batch [26/130] mAP: 0.42088\n",
      "Batch [27/130] mAP: 0.42518\n",
      "Batch [28/130] mAP: 0.42229\n",
      "Batch [29/130] mAP: 0.42813\n",
      "Batch [30/130] mAP: 0.42571\n",
      "Batch [31/130] mAP: 0.42703\n",
      "Batch [32/130] mAP: 0.42138\n",
      "Batch [33/130] mAP: 0.42049\n",
      "Batch [34/130] mAP: 0.42164\n",
      "Batch [35/130] mAP: 0.42263\n",
      "Batch [36/130] mAP: 0.42356\n",
      "Batch [37/130] mAP: 0.42437\n",
      "Batch [38/130] mAP: 0.42634\n",
      "Batch [39/130] mAP: 0.42866\n",
      "Batch [40/130] mAP: 0.42898\n",
      "Batch [41/130] mAP: 0.42785\n",
      "Batch [42/130] mAP: 0.42927\n",
      "Batch [43/130] mAP: 0.43240\n",
      "Batch [44/130] mAP: 0.42857\n",
      "Batch [45/130] mAP: 0.42339\n",
      "Batch [46/130] mAP: 0.42342\n",
      "Batch [47/130] mAP: 0.42105\n",
      "Batch [48/130] mAP: 0.42038\n",
      "Batch [49/130] mAP: 0.41956\n",
      "Batch [50/130] mAP: 0.42088\n",
      "Batch [51/130] mAP: 0.42054\n",
      "Batch [52/130] mAP: 0.41974\n",
      "Batch [53/130] mAP: 0.41910\n",
      "Batch [54/130] mAP: 0.41716\n",
      "Batch [55/130] mAP: 0.41833\n",
      "Batch [56/130] mAP: 0.41860\n",
      "Batch [57/130] mAP: 0.42122\n",
      "Batch [58/130] mAP: 0.42174\n",
      "Batch [59/130] mAP: 0.42171\n",
      "Batch [60/130] mAP: 0.42069\n",
      "Batch [61/130] mAP: 0.42040\n",
      "Batch [62/130] mAP: 0.41999\n",
      "Batch [63/130] mAP: 0.42042\n",
      "Batch [64/130] mAP: 0.42064\n",
      "Batch [65/130] mAP: 0.41937\n",
      "Batch [66/130] mAP: 0.42092\n",
      "Batch [67/130] mAP: 0.42160\n",
      "Batch [68/130] mAP: 0.42182\n",
      "Batch [69/130] mAP: 0.42218\n",
      "Batch [70/130] mAP: 0.42333\n",
      "Batch [71/130] mAP: 0.42448\n",
      "Batch [72/130] mAP: 0.42134\n",
      "Batch [73/130] mAP: 0.42226\n",
      "Batch [74/130] mAP: 0.42204\n",
      "Batch [75/130] mAP: 0.42107\n",
      "Batch [76/130] mAP: 0.42077\n",
      "Batch [77/130] mAP: 0.42061\n",
      "Batch [78/130] mAP: 0.41868\n",
      "Batch [79/130] mAP: 0.41749\n",
      "Batch [80/130] mAP: 0.41829\n",
      "Batch [81/130] mAP: 0.41858\n",
      "Batch [82/130] mAP: 0.41896\n",
      "Batch [83/130] mAP: 0.41859\n",
      "Batch [84/130] mAP: 0.41728\n",
      "Batch [85/130] mAP: 0.41818\n",
      "Batch [86/130] mAP: 0.41836\n",
      "Batch [87/130] mAP: 0.42069\n",
      "Batch [88/130] mAP: 0.42085\n",
      "Batch [89/130] mAP: 0.41991\n",
      "Batch [90/130] mAP: 0.41984\n",
      "Batch [91/130] mAP: 0.41962\n",
      "Batch [92/130] mAP: 0.41943\n",
      "Batch [93/130] mAP: 0.42047\n",
      "Batch [94/130] mAP: 0.42089\n",
      "Batch [95/130] mAP: 0.42076\n",
      "Batch [96/130] mAP: 0.42095\n",
      "Batch [97/130] mAP: 0.42126\n",
      "Batch [98/130] mAP: 0.42126\n",
      "Batch [99/130] mAP: 0.41926\n",
      "Batch [100/130] mAP: 0.41958\n",
      "Batch [101/130] mAP: 0.41872\n",
      "Batch [102/130] mAP: 0.41825\n",
      "Batch [103/130] mAP: 0.41853\n",
      "Batch [104/130] mAP: 0.41795\n",
      "Batch [105/130] mAP: 0.41667\n",
      "Batch [106/130] mAP: 0.41805\n",
      "Batch [107/130] mAP: 0.41769\n",
      "Batch [108/130] mAP: 0.41700\n",
      "Batch [109/130] mAP: 0.41618\n",
      "Batch [110/130] mAP: 0.41708\n",
      "Batch [111/130] mAP: 0.41829\n",
      "Batch [112/130] mAP: 0.41836\n",
      "Batch [113/130] mAP: 0.41885\n",
      "Batch [114/130] mAP: 0.41919\n",
      "Batch [115/130] mAP: 0.42018\n",
      "Batch [116/130] mAP: 0.42049\n",
      "Batch [117/130] mAP: 0.42073\n",
      "Batch [118/130] mAP: 0.42195\n",
      "Batch [119/130] mAP: 0.42124\n",
      "Batch [120/130] mAP: 0.42106\n",
      "Batch [121/130] mAP: 0.42140\n",
      "Batch [122/130] mAP: 0.42244\n",
      "Batch [123/130] mAP: 0.42264\n",
      "Batch [124/130] mAP: 0.42361\n",
      "Batch [125/130] mAP: 0.42446\n",
      "Batch [126/130] mAP: 0.42571\n",
      "Batch [127/130] mAP: 0.42602\n",
      "Batch [128/130] mAP: 0.42467\n",
      "Batch [129/130] mAP: 0.42459\n",
      "Mean Average Precision: 0.42459\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    config = {}\n",
    "    config[\"batch_size\"] = 16\n",
    "    config['backbone_name'] = \"darknet_53\"\n",
    "    config['backbone_pretrained'] = \"\"\n",
    "    config['anchors'] = [[[116, 90], [156, 198], [373, 326]],\n",
    "                                [[30, 61], [62, 45], [59, 119]],\n",
    "                                [[10, 13], [16, 30], [33, 23]]]\n",
    "    config['classes'] = 20\n",
    "    config['img_h'] = config['img_w'] = 416\n",
    "    config['confidence_threshold'] = 0.5\n",
    "    config['pretrain_snapshot'] = \"./states/20190602203613/model.pth\"\n",
    "    config['classes_names_path'] = \"./data/voc.names\"\n",
    "\n",
    "    # Start training\n",
    "    evaluate(config)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
