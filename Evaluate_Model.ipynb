{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import importlib\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from yolo_model import yoloModel\n",
    "from yolo_model_dcnn import dcnnyoloModel\n",
    "from PASCAL_Dataloader import create_split_loaders\n",
    "from YOLO_Loss import YoloLoss\n",
    "from utils import NMS\n",
    "from bbox import bbox_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(config, architecture='Baseline'):\n",
    "    \n",
    "    # Check if your system supports CUDA\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    \n",
    "    # Setup GPU optimization if CUDA is supported\n",
    "    if use_cuda:\n",
    "        computing_device = torch.device(\"cuda\")\n",
    "        extras = {\"num_workers\": 3, \"pin_memory\": True}\n",
    "        print(\"CUDA is supported\")\n",
    "    else: # Otherwise, train on the CPU\n",
    "        computing_device = torch.device(\"cpu\")\n",
    "        extras = False\n",
    "        print(\"CUDA NOT supported\")\n",
    "        \n",
    "    # Load and initialize network\n",
    "    if architecture == \"Baseline\":\n",
    "        net = yoloModel(config)\n",
    "    elif architecture == \"DeformConv\":\n",
    "        net = dcnnyoloModel(config)\n",
    "    else:\n",
    "        print('Error: Incorrect architecture')\n",
    "    \n",
    "    net = net.to(computing_device)\n",
    "\n",
    "    # Restore pretrain model\n",
    "    if config[\"pretrain_snapshot\"]:\n",
    "        state_dict = torch.load(config[\"pretrain_snapshot\"])\n",
    "        net.load_state_dict(state_dict)\n",
    "    else:\n",
    "        print(\"Error: missing pretrain_snapshot\")\n",
    "\n",
    "    # Calculate YOLO loss at 3 different scales\n",
    "    YOLO_losses = []\n",
    "    for i in range(3):\n",
    "        YOLO_losses.append(YoloLoss(config[\"classes\"], (config[\"img_w\"], config[\"img_h\"]), config[\"anchors\"][i]))\n",
    "\n",
    "    # Test DataLoader\n",
    "    root_dir = os.getcwd()\n",
    "    train_loader, val_loader, test_loader = create_split_loaders(config['batch_size'])\n",
    "\n",
    "    # Start the eval loop\n",
    "    print(\"Start eval.\")\n",
    "    count = 0\n",
    "    correct = 0\n",
    "    for n, samples in enumerate(test_loader):\n",
    "        images, labels = samples[\"image\"], samples[\"label\"]\n",
    "        images, labels = images.to(computing_device), labels.to(computing_device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = net(images)\n",
    "            list_of_outputs = []\n",
    "            for i in range(3):\n",
    "                list_of_outputs.append(YOLO_losses[i](outputs[i]))\n",
    "            final_output = torch.cat(list_of_outputs, 1)\n",
    "            final_output = NMS(final_output, config[\"classes\"], conf_thresh=0.2)\n",
    "            \n",
    "            #  Calculate mAP\n",
    "            for i in range(labels.size(0)):\n",
    "                \n",
    "                # Get the labels for samples where the width is not zero\n",
    "                t_samp = labels[i, labels[i, :, 3] != 0]\n",
    "                for obj_class, t_x, t_y, t_w, t_h in t_samp:\n",
    "                    count += 1\n",
    "                    \n",
    "                    # Obtain rescaled ground truth coordinates\n",
    "                    t_xmin, t_xmax = config[\"img_w\"] * (t_x - t_w / 2), config[\"img_w\"] * (t_x + t_w / 2)\n",
    "                    t_ymin, t_ymax = config[\"img_h\"] * (t_y - t_h / 2), config[\"img_h\"] * (t_y + t_h / 2)\n",
    "                    \n",
    "                    ground_truth_box = torch.cat([coord.unsqueeze(0) for coord in [t_xmin, t_ymin, t_xmax, t_ymax]]).view(1, -1)\n",
    "                    ground_truth_box = ground_truth_box.float()\n",
    "                    samp_pred = final_output[i]\n",
    "                    if samp_pred is not None:\n",
    "                        \n",
    "                        # Find IOU of predictions where the class predicted is same as ground truth\n",
    "                        for xmin, ymin, xmax, ymax, conf, obj_conf, obj_pred in samp_pred[samp_pred[:, 6] == obj_class.float()]:\n",
    "                            box_pred = torch.cat([coord.unsqueeze(0) for coord in [xmin, ymin, xmax, ymax]]).view(1, -1)\n",
    "                            #print('Pred:',box_pred)\n",
    "                            #print('GT:',box_gt)\n",
    "                            iou = bbox_iou(box_pred, ground_truth_box)\n",
    "                            if iou >= config[\"confidence_threshold\"]:\n",
    "                                correct += 1\n",
    "                                break\n",
    "        if count:\n",
    "            print('Batch [%d/%d] mAP: %.5f' % (n, len(test_loader), float(correct / count)))\n",
    "\n",
    "    print('Mean Average Precision: %.5f' % float(correct / count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n",
      "Start eval.\n",
      "Batch [0/130] mAP: 0.73529\n",
      "Batch [1/130] mAP: 0.70000\n",
      "Batch [2/130] mAP: 0.67153\n",
      "Batch [3/130] mAP: 0.64216\n",
      "Batch [4/130] mAP: 0.62348\n",
      "Batch [5/130] mAP: 0.62162\n",
      "Batch [6/130] mAP: 0.62029\n",
      "Batch [7/130] mAP: 0.61942\n",
      "Batch [8/130] mAP: 0.60731\n",
      "Batch [9/130] mAP: 0.61588\n",
      "Batch [10/130] mAP: 0.62351\n",
      "Batch [11/130] mAP: 0.62289\n",
      "Batch [12/130] mAP: 0.61217\n",
      "Batch [13/130] mAP: 0.61011\n",
      "Batch [14/130] mAP: 0.61265\n",
      "Batch [15/130] mAP: 0.61029\n",
      "Batch [16/130] mAP: 0.60328\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    config = {}\n",
    "    config[\"batch_size\"] = 16\n",
    "    config['backbone_name'] = \"darknet_53\"\n",
    "    config['backbone_pretrained'] = \"\"\n",
    "    config['anchors'] = [[[116, 90], [156, 198], [373, 326]],\n",
    "                                [[30, 61], [62, 45], [59, 119]],\n",
    "                                [[10, 13], [16, 30], [33, 23]]]\n",
    "    config['classes'] = 20\n",
    "    config['img_h'] = config['img_w'] = 416\n",
    "    config['confidence_threshold'] = 0.5\n",
    "    config['pretrain_snapshot'] = \"deformconv_weights.pth\"\n",
    "    config['classes_names_path'] = \"./data/voc.names\"\n",
    "\n",
    "    # Start training\n",
    "    evaluate(config, architecture='DeformConv')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
